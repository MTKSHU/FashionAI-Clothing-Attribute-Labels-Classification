{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] Loss: 0.42389, Acc: 86.35, Time: 3.4 s\n",
      "[2/50] Loss: 0.10881, Acc: 96.67, Time: 3.7 s\n",
      "[3/50] Loss: 0.08289, Acc: 97.48, Time: 3.5 s\n",
      "[4/50] Loss: 0.06887, Acc: 97.89, Time: 3.7 s\n",
      "[5/50] Loss: 0.06077, Acc: 98.09, Time: 3.5 s\n",
      "[6/50] Loss: 0.05484, Acc: 98.31, Time: 3.8 s\n",
      "[7/50] Loss: 0.04954, Acc: 98.45, Time: 3.6 s\n",
      "[8/50] Loss: 0.04534, Acc: 98.57, Time: 3.7 s\n",
      "[9/50] Loss: 0.04253, Acc: 98.67, Time: 3.6 s\n",
      "[10/50] Loss: 0.04110, Acc: 98.71, Time: 3.7 s\n",
      "[11/50] Loss: 0.03782, Acc: 98.77, Time: 3.6 s\n",
      "[12/50] Loss: 0.03587, Acc: 98.87, Time: 3.6 s\n",
      "[13/50] Loss: 0.03356, Acc: 98.88, Time: 3.6 s\n",
      "[14/50] Loss: 0.03267, Acc: 98.94, Time: 3.6 s\n",
      "[15/50] Loss: 0.03037, Acc: 99.04, Time: 3.6 s\n",
      "[16/50] Loss: 0.02808, Acc: 99.11, Time: 3.5 s\n",
      "[17/50] Loss: 0.02749, Acc: 99.14, Time: 3.4 s\n",
      "[18/50] Loss: 0.02691, Acc: 99.10, Time: 3.6 s\n",
      "[19/50] Loss: 0.02525, Acc: 99.16, Time: 3.5 s\n",
      "[20/50] Loss: 0.02455, Acc: 99.20, Time: 3.5 s\n",
      "[21/50] Loss: 0.02329, Acc: 99.23, Time: 3.5 s\n",
      "[22/50] Loss: 0.02152, Acc: 99.29, Time: 3.6 s\n",
      "[23/50] Loss: 0.02143, Acc: 99.32, Time: 3.5 s\n",
      "[24/50] Loss: 0.02045, Acc: 99.33, Time: 3.4 s\n",
      "[25/50] Loss: 0.01931, Acc: 99.39, Time: 3.4 s\n",
      "[26/50] Loss: 0.01956, Acc: 99.36, Time: 3.5 s\n",
      "[27/50] Loss: 0.01907, Acc: 99.36, Time: 3.5 s\n",
      "[28/50] Loss: 0.01744, Acc: 99.40, Time: 3.5 s\n",
      "[29/50] Loss: 0.01684, Acc: 99.43, Time: 3.7 s\n",
      "[30/50] Loss: 0.01576, Acc: 99.49, Time: 4.0 s\n",
      "[31/50] Loss: 0.01711, Acc: 99.39, Time: 4.1 s\n",
      "[32/50] Loss: 0.01573, Acc: 99.46, Time: 3.5 s\n",
      "[33/50] Loss: 0.01597, Acc: 99.44, Time: 3.5 s\n",
      "[34/50] Loss: 0.01551, Acc: 99.45, Time: 4.4 s\n",
      "[35/50] Loss: 0.01424, Acc: 99.54, Time: 3.7 s\n",
      "[36/50] Loss: 0.01306, Acc: 99.56, Time: 3.5 s\n",
      "[37/50] Loss: 0.01376, Acc: 99.51, Time: 3.4 s\n",
      "[38/50] Loss: 0.01328, Acc: 99.52, Time: 4.0 s\n",
      "[39/50] Loss: 0.01250, Acc: 99.54, Time: 4.5 s\n",
      "[40/50] Loss: 0.01212, Acc: 99.60, Time: 3.5 s\n",
      "[41/50] Loss: 0.01381, Acc: 99.50, Time: 4.2 s\n",
      "[42/50] Loss: 0.01245, Acc: 99.59, Time: 4.0 s\n",
      "[43/50] Loss: 0.01067, Acc: 99.61, Time: 3.8 s\n",
      "[44/50] Loss: 0.01067, Acc: 99.66, Time: 3.6 s\n",
      "[45/50] Loss: 0.00985, Acc: 99.66, Time: 3.3 s\n",
      "[46/50] Loss: 0.01216, Acc: 99.58, Time: 3.5 s\n",
      "[47/50] Loss: 0.00961, Acc: 99.66, Time: 3.8 s\n",
      "[48/50] Loss: 0.01073, Acc: 99.64, Time: 3.8 s\n",
      "[49/50] Loss: 0.01136, Acc: 99.56, Time: 3.6 s\n",
      "[50/50] Loss: 0.00965, Acc: 99.65, Time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epoches = 50\n",
    "\n",
    "trans_img = transforms.ToTensor()\n",
    "\n",
    "trainset = MNIST('./data', train=True, transform=trans_img)\n",
    "testset = MNIST('./data', train=False, transform=trans_img)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# build network\n",
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(400, 120),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "lenet = Lenet()\n",
    "lenet.cuda()\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = optim.SGD(lenet.parameters(), lr=learning_rate)\n",
    "\n",
    "# train\n",
    "for i in range(epoches):\n",
    "    since = time.time()\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    for (img, label) in trainloader:\n",
    "        img = Variable(img).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = lenet(img)\n",
    "        loss = criterian(output, label)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        _, predict = torch.max(output, 1)\n",
    "        correct_num = (predict == label).sum()\n",
    "        running_acc += correct_num.data[0]\n",
    "    \n",
    "    running_loss /= len(trainset)\n",
    "    running_acc /= len(trainset)\n",
    "    print(\"[%d/%d] Loss: %.5f, Acc: %.2f, Time: %.1f s\" %(i+1, epoches, running_loss, 100*running_acc, time.time()-since))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.07444, Acc: 98.46 %\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "lenet.eval()\n",
    "\n",
    "testloss = 0.\n",
    "testacc = 0.\n",
    "for (img, label) in testloader:\n",
    "    img = Variable(img).cuda()\n",
    "    label = Variable(label).cuda()\n",
    "    \n",
    "    output = lenet(img)\n",
    "    loss = criterian(output, label)\n",
    "    testloss += loss.data[0]\n",
    "    _, predict = torch.max(output, 1)\n",
    "    num_correct = (predict == label).sum()\n",
    "    testacc += num_correct.data[0]\n",
    "\n",
    "testloss /= len(testset)\n",
    "testacc /= len(testset)\n",
    "print(\"Test: Loss: %.5f, Acc: %.2f %%\" %(testloss, 100*testacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
