{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法:使用Keras提供的其他优化器，如梯度下降，看在其他算法下模型参数对模型训练和过拟合的速度有怎样的影响。\n",
    "损失函数:尝试使用Keras其他可用的损失函数，探究选用其他的损失函数是否可以提升模型的性能。\n",
    "学习率与迭代次数更新策略\n",
    "更大的Batch Size:使用更大的Batch Size意味着模型在训练集和测试集上的数据操作规模更大了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "  0%|          | 13/89683 [00:00<11:34, 129.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入图像到内存..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89683/89683 [21:43<00:00, 68.82it/s]\n",
      "  2%|▏         | 1619/89683 [00:00<00:05, 16183.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像已载入内存,开始载入转换的标签..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89683/89683 [00:13<00:00, 6738.83it/s] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [89683, 8]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2ed8f41b4d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m X_train, X_valid, y_train, y_valid = train_test_split(XX, \n\u001b[0;32m--> 144\u001b[0;31m         yy, test_size=0.1, random_state=50)\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_tf_keras/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_tf_keras/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_tf_keras/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [89683, 8]"
     ]
    }
   ],
   "source": [
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from keras.layers import *\n",
    "#from keras.layers import Input\n",
    "from keras.models import *\n",
    "#from keras.models import Model\n",
    "#from keras.layers import Input, Dense\n",
    "#a = Input(shape=(32,))\n",
    "#b = Dense(32)(a)\n",
    "#model = Model(inputs=a, outputs=b)\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras import initializers\n",
    "from keras.applications import *\n",
    "\n",
    "#from keras.utils import multi_gpu_model \n",
    "#from keras.applications import ResNet50\n",
    "#from keras.applications import VGG16\n",
    "#from keras.applications import VGG19\n",
    "#from keras.applications import Xception # TensorFlow ONLY\n",
    "#from keras.applications import InceptionResNetV2\n",
    "#from keras.applications import InceptionV3\n",
    "\n",
    "#tf.keras.applications.inception_v3.InceptionV3\n",
    "#tf.keras.applications.inception_resnet_v2.InceptionResNetV2\n",
    "####################################################################\n",
    "#设置GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "#设置项\n",
    "#看具体的模型参数设置在:https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "MODELS = {\"ResNet50\":ResNet50}\n",
    "#MODELS = {\"NASNetLarge\":NASNetLarge,\"VGG16\":VGG16}\n",
    "#\"InceptionV3\":InceptionV3,\"DenseNet121\":DenseNet121,\n",
    " #       \"DenseNet169\":DenseNet169,\"DenseNet201\":DenseNet201,\"Xception\":Xception, \n",
    " #       \"InceptionResNetV2\":InceptionResNetV2,\n",
    "#\"ResNet50\":ResNet50, \n",
    "#\"VGG16\":VGG16,\"VGG16\":VGG19,\"NASNetMobile\":NASNetMobile\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "classes = ['coat_length_labels','collar_design_labels', 'lapel_design_labels',\n",
    "           'neck_design_labels','neckline_design_labels',\n",
    "           'pant_length_labels', 'skirt_length_labels', \n",
    "           'sleeve_length_labels']    \n",
    "fai_result = []\n",
    "label_count = {'coat_length_labels':8,\n",
    "               'collar_design_labels':5, \n",
    "               'lapel_design_labels':5,\n",
    "               'neck_design_labels':5,\n",
    "               'neckline_design_labels':10,\n",
    "               'pant_length_labels':6, \n",
    "               'skirt_length_labels':6, \n",
    "               'sleeve_length_labels':9}\n",
    "#####################\n",
    "width = 299\n",
    "#####################\n",
    "#X = {}\n",
    "#y = {}\n",
    "#df_train = {}\n",
    "#df_load = {}\n",
    "#for cur_class in classes:\n",
    "   # df_train[cur_class] = pd.read_csv('../train/Annotations/{0}.csv'.format(cur_class), header=None)\n",
    "   # X[cur_class] = np.zeros((len(df_train[cur_class]), width, width, 3), dtype=np.uint8)\n",
    "    #y[cur_class] = np.zeros((len(df_train[cur_class]), label_count[cur_class]), dtype=np.uint8)\n",
    "    \n",
    "    #df_train[cur_class].columns = ['image_id', 'class', 'label']\n",
    "    #df_load[cur_class] = df_train[cur_class].copy()\n",
    "    #df_load[cur_class].reset_index(inplace=True)\n",
    "    #del df_load[cur_class]['index']\n",
    "    #样本总数 \n",
    "    #print(\"各类样本总数{0}:{1}\".format(cur_class,len(df_load[cur_class])))\n",
    "    \n",
    "df = pd.read_csv('../train/Annotations/train.csv', header=None)\n",
    "df.columns = ['image_id', 'class', 'label']\n",
    "dfl = df.copy()\n",
    "dfl.reset_index(inplace=True)\n",
    "del dfl['index']\n",
    "nn = len(dfl)\n",
    "XX = np.zeros((nn, width, width, 3), dtype=np.uint8)\n",
    "    \n",
    "#yyy = np.zeros((nn, 8, 5, 5, 5, 10, 6, 6, 9), dtype=np.uint8)\n",
    "    \n",
    "yy = [np.zeros((nn, label_count[x])) for x in label_count.keys()]\n",
    "#print(yy)\n",
    "print(\"载入图像到内存..\") \n",
    "for i in tqdm(range(nn)):\n",
    "        \n",
    "        \n",
    "    #n_class = len(df_load['label'][0])\n",
    "    #if len(tmp_label) == label_count[df_load['class'][i]]:\n",
    "    XX[i] = cv2.resize(cv2.imread('../train/{0}'.format(dfl['image_id'][i])), (width, width))\n",
    "print(\"图像已载入内存,开始载入转换的标签..\")    \n",
    "for i in tqdm(range(nn)):\n",
    "        \n",
    "    tmp_label = dfl['label'][i]\n",
    "    if dfl['class'][i] == 'coat_length_labels':\n",
    "        yy[0][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'collar_design_labels':\n",
    "        yy[1][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'lapel_design_labels':\n",
    "        yy[2][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'neck_design_labels':\n",
    "        yy[3][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'neckline_design_labels':\n",
    "        yy[4][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'pant_length_labels':\n",
    "        yy[5][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'skirt_length_labels':\n",
    "        yy[6][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    else:\n",
    "        yy[7][i][tmp_label.find('y')] = 1\n",
    "          \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(XX, \n",
    "        yy, test_size=0.1, random_state=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for KEY, MODLE in MODELS.items():\n",
    "    \n",
    "    \n",
    "    #为299*299,设置如下\n",
    "    ppreprocess = preprocess_input\n",
    "    if KEY in [\"InceptionV3\",\"Xception\", \"InceptionResNetV2\"]:\n",
    "        width = 299\n",
    "    elif KEY == \"NASNetLarge\":\n",
    "        width = 331\n",
    "    else:\n",
    "        width = 224\n",
    "        ppreprocess = imagenet_utils.preprocess_input \n",
    "    print('######################在{0}下训练8个分类器####################'.format(KEY))\n",
    "    cnn_model = MODLE(include_top=False, input_shape=(width, width, 3), weights='imagenet',pooling='avg')\n",
    "    inputs = Input((width, width, 3))\n",
    "    x = inputs\n",
    "    x = Lambda(ppreprocess, name='preprocessing')(x)\n",
    "    x = cnn_model(x)\n",
    "        #下面是新加的层\n",
    "        #x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "        #x = Flatten(name='flatten')(x)\n",
    "        #x = Dense(2048, activation='relu', name='fc1')(x)\n",
    "        # n_class为对应属性的分类个数\n",
    "        #x = Dense(256, activation='relu', kernel_initializer=initializers.he_uniform(seed=None),name='fc1')(x)\n",
    "        #x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "    #x = Dense(512, activation='relu', kernel_initializer=initializers.he_uniform(seed=None),name='fc2')(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = [Dense(count, activation='softmax', name=name)(x) for name, count in label_count.items()]\n",
    "    model = Model(inputs, x)\n",
    "    adam = Adam(lr=0.001)\n",
    "\n",
    "        #多GPU训练,因为keras设计的自动保存最好模型,但是多GPU训练,其save()就没法用了\n",
    "        #model = multi_gpu_model(model, 2)  \n",
    "\n",
    "    model.compile(optimizer=adam,\n",
    "                    loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "    print(\"模型初始化完毕\") \n",
    "    \n",
    "\n",
    "        #sgd = SGD(lr=learning_rate, decay=learning_rate/nb_epoch, momentum=0.9, nesterov=True)\n",
    "        #adam = optimizers.Adam(lr=1e-4)\n",
    "        #optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "       \n",
    "    # Callback that implements learning rate schedule\n",
    "    #schedule = Step([20], [1e-4, 1e-6])\n",
    "    #history = model.fit(X_train, Y_train,\n",
    "    #                    batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test,Y_test),\n",
    "    #                    callbacks=[\n",
    "    #                           schedule,\n",
    "    #                           keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "\n",
    "    # 该回调函数将在每个epoch后保存模型到filepath\n",
    "    #keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "    # 当监测值不再改善时，该回调函数将中止训练.\n",
    "    #当early stop被激活（如发现loss相比上一个epoch训练没有下降），则经过patience个epoch后停止训练\n",
    "    #keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "        #设置训练完之后,最好的模型保存路径\n",
    "        #checkpointer = ModelCheckpoint(filepath='../models/{0}.best.h5'.format(KEY), verbose=1, \n",
    "                #                        save_best_only=True)\n",
    "        #训练开始,并保存训练过程的loss和acc变化\n",
    "    h = model.fit(X_train, y_train, batch_size=8, epochs=32, \n",
    "                      #callbacks=[EarlyStopping(patience=12), checkpointer], \n",
    "                      shuffle=True, \n",
    "                      validation_data=(X_valid,y_valid))\n",
    "    print(\"模型训练完毕!\")\n",
    "    #保存模型\n",
    "    print(\"开始保存模型\")\n",
    "    model.save_weights('../model.h5')\n",
    "    print(\"下面开始测试\")\n",
    "    df_test = pd.read_csv('../test/Tests/question.csv', header=None)\n",
    "    df_test.columns = ['image_id', 'class', 'x']\n",
    "    del df_test['x']  \n",
    "    df_load = df_test.copy()\n",
    "    df_load.reset_index(inplace=True)\n",
    "    del df_load['index']  \n",
    "    nn = len(df_load)\n",
    "    X_test = np.zeros((nn, width, width, 3), dtype=np.uint8)\n",
    "    print(\"载入测试集图像到内存\")\n",
    "    for i in tqdm(range(nn)):\n",
    "        X_test[i] = cv2.resize(cv2.imread('../test/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "        #测试集上预测并输出结果\n",
    "    test_np = model.predict(X_test, batch_size=128)\n",
    "    print(test_np)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reasult = [np.zeros((nn, label_count[x])) for x in label_count.keys()]\n",
    "result = []\n",
    "for i in tqdm(range(nn)):\n",
    "        \n",
    "    #tmp_label = df_load['label'][i]\n",
    "    #n_class = len(df_load['label'][0])\n",
    "    #if len(tmp_label) == label_count[df_load['class'][i]]:\n",
    "    tmp_result = ''\n",
    "    if df_load['class'][i] == 'coat_length_labels':\n",
    "        tmp_listdd = test_np[0][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "            \n",
    "    elif df_load['class'][i] == 'collar_design_labels':\n",
    "        tmp_listdd = test_np[1][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "        \n",
    "    elif df_load['class'][i] == 'lapel_design_labels':\n",
    "        tmp_listdd = test_np[2][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "        \n",
    "    elif df_load['class'][i] == 'neck_design_labels':\n",
    "        tmp_listdd = test_np[3][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "        \n",
    "            \n",
    "    elif df_load['class'][i] == 'neckline_design_labels':\n",
    "        tmp_listdd = test_np[4][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "        \n",
    "    elif df_load['class'][i] == 'pant_length_labels':\n",
    "        tmp_listdd = test_np[5][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "        \n",
    "    elif df_load['class'][i] == 'skirt_length_labels':\n",
    "        tmp_listdd = test_np[6][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "        \n",
    "    else:\n",
    "        tmp_listdd = test_np[7][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "\n",
    "df_load['result'] = result     \n",
    "df_load.to_csv('../result/{0}/{0}.csv'.format(KEY), header=None, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"打印原预测列表:\")\n",
    "print(test_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
