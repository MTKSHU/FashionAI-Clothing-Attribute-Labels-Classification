{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法:使用Keras提供的其他优化器，如梯度下降，看在其他算法下模型参数对模型训练和过拟合的速度有怎样的影响。\n",
    "损失函数:尝试使用Keras其他可用的损失函数，探究选用其他的损失函数是否可以提升模型的性能。\n",
    "学习率与迭代次数更新策略\n",
    "更大的Batch Size:使用更大的Batch Size意味着模型在训练集和测试集上的数据操作规模更大了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T08:41:21.349586Z",
     "start_time": "2018-04-11T08:41:19.287596Z"
    }
   },
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from keras.layers import *\n",
    "#from keras.layers import Input\n",
    "from keras.models import *\n",
    "#from keras.models import Model\n",
    "#from keras.layers import Input, Dense\n",
    "#a = Input(shape=(32,))\n",
    "#b = Dense(32)(a)\n",
    "#model = Model(inputs=a, outputs=b)\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras import initializers\n",
    "from keras.applications import *\n",
    "\n",
    "import Augmentor\n",
    "plt.ion()   # interactive mode 画图不阻止程序运行\n",
    "#from keras.utils import multi_gpu_model \n",
    "#from keras.applications import ResNet50\n",
    "#from keras.applications import VGG16\n",
    "#from keras.applications import VGG19\n",
    "#from keras.applications import Xception # TensorFlow ONLY\n",
    "#from keras.applications import InceptionResNetV2\n",
    "#from keras.applications import InceptionV3\n",
    "\n",
    "#tf.keras.applications.inception_v3.InceptionV3\n",
    "#tf.keras.applications.inception_resnet_v2.InceptionResNetV2\n",
    "####################################################################\n",
    "#设置GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "#设置项\n",
    "#看具体的模型参数设置在:https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "MODELS = {\"InceptionResNetV2\":InceptionResNetV2}\n",
    "#MODELS = {\"DenseNet121\":DenseNet121,\"DenseNet201\":DenseNet201,\"InceptionResNetV2\":InceptionResNetV2}\n",
    "#\"InceptionV3\":InceptionV3,\"DenseNet121\":DenseNet121,\n",
    " #       \"DenseNet169\":DenseNet169,\"DenseNet201\":DenseNet201,\"Xception\":Xception, \n",
    " #       \"InceptionResNetV2\":InceptionResNetV2,\n",
    "#\"ResNet50\":ResNet50, \n",
    "#\"VGG16\":VGG16,\"VGG16\":VGG19,\"NASNetMobile\":NASNetMobile\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "classes = ['collar_design_labels', 'neckline_design_labels', 'skirt_length_labels', \n",
    "           'sleeve_length_labels', 'neck_design_labels', 'lapel_design_labels', \n",
    "           'pant_length_labels','coat_length_labels']   \n",
    "#classes = ['pant_length_labels','coat_length_labels']    \n",
    "fai_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-11T08:41:19.288Z"
    }
   },
   "outputs": [],
   "source": [
    "p = Augmentor.Pipeline()\n",
    "p.flip_left_right(probability=0.6)\n",
    "#p.random_distortion(probability=0.8, grid_width=4, grid_height=4, magnitude=4)\n",
    "#p.skew(probability=0.4, magnitude=0.2)\n",
    "#p.crop_random(probability=0.8, percentage_area=0.95)\n",
    "#p.skew_left_right(probability=1, magnitude=0.5) #1代表45度\n",
    "#p.rotate(probability=0.7, max_left_rotation=8, max_right_rotation=8)\n",
    "#p.zoom(probability=0.8, min_factor=1.1, max_factor=1.2)\n",
    "#p.skew_top_bottom(probability=0.5, magnitude=1)\n",
    "#p.skew_corner(probability=0.5, magnitude=1)\n",
    "for KEY, MODLE in MODELS.items():\n",
    "    #\n",
    "    #为299*299,设置如下\n",
    "    ppreprocess = preprocess_input\n",
    "    if KEY in [\"InceptionV3\",\"Xception\", \"InceptionResNetV2\"]:\n",
    "        width = 299\n",
    "    elif KEY == \"NASNetLarge\":\n",
    "        width = 331\n",
    "    else:\n",
    "        width = 224\n",
    "        ppreprocess = imagenet_utils.preprocess_input \n",
    "    print('######################在{0}下训练8个分类器####################'.format(KEY))\n",
    "    for cur_class in classes:\n",
    "        print('#######{0}:{1}####################'.format(KEY,cur_class ))\n",
    "        df_train = pd.read_csv('../train/Annotations/{0}.csv'.format(cur_class), header=None)\n",
    "        df_train.columns = ['image_id', 'class', 'label']\n",
    "        df_load = df_train.copy()\n",
    "        df_load.reset_index(inplace=True)\n",
    "        del df_load['index']\n",
    "        print(\"选择的属性为:{0}, 种类的为:{1},样本数: {2}\".format(cur_class , len(df_load['label'][0]),len(df_load)))\n",
    "        \n",
    "        n = len(df_load)\n",
    "        n_class = len(df_load['label'][0])\n",
    "        prefix_cls = cur_class.split('_')[0]\n",
    "        \n",
    "        X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "        y = np.zeros((n, n_class), dtype=np.uint8)\n",
    "        for i in range(n):\n",
    "            tmp_label = df_load['label'][i]\n",
    "            if len(tmp_label) > n_class:\n",
    "                print(df_load['image_id'][i])\n",
    "            X[i] = cv2.resize(cv2.imread('../train/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "            y[i][tmp_label.find('y')] = 1\n",
    "        print(\"数据装载到内存完毕:{0},{1}\".format(KEY,cur_class))\n",
    "        #plt.figure(figsize=(12, 7))\n",
    "        #for i in range(8):\n",
    "            #random_index = random.randint(0, n-1)\n",
    "            #plt.subplot(2, 4, i+1)\n",
    "            #plt.imshow(X[random_index][:,:,::-1])\n",
    "            #plt.title(y[random_index])\n",
    "        #plt.savefig('../images/{0}/{0}_{1}.png'.format(prefix_cls, KEY),bbox_inches='tight')\n",
    "        \n",
    "        #设置模型的finetune细节\n",
    "        cnn_model = MODLE(include_top=False, input_shape=(width, width, 3), weights='imagenet',pooling='avg')\n",
    "        inputs = Input((width, width, 3))\n",
    "        x = inputs\n",
    "        x = Lambda(ppreprocess, name='preprocessing')(x)\n",
    "        x = cnn_model(x)\n",
    "        #下面是新加的层\n",
    "        #x = GlobalAveragePooling2D()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        #x = Flatten(name='flatten')(x)\n",
    "        x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "        # n_class为对应属性的分类个数\n",
    "        x = Dense(512, activation='relu', kernel_initializer=initializers.he_uniform(seed=None),name='fc2')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "        model = Model(inputs, x)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=50)\n",
    "        \n",
    "        \n",
    "        sgd = SGD(lr=0.01, decay=0.01/40, momentum=0.9, nesterov=True)\n",
    "        #adam = optimizers.Adam(lr=1e-4)\n",
    "        #optimizer=sgd(lr=0.001, momentum=0.9, nesterov=True))\n",
    "        #adam = Adam(lr=0.0001)\n",
    "        \n",
    "        #多GPU训练,因为keras设计的自动保存最好模型,但是多GPU训练,其save()就没法用了\n",
    "        #model = multi_gpu_model(model, 2)  \n",
    "\n",
    "        model.compile(optimizer=sgd,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Callback that implements learning rate schedule\n",
    "#schedule = Step([20], [1e-4, 1e-6])\n",
    "#history = model.fit(X_train, Y_train,\n",
    "#                    batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test,Y_test),\n",
    "#                    callbacks=[\n",
    "#                           schedule,\n",
    "#                           keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "\n",
    "# 该回调函数将在每个epoch后保存模型到filepath\n",
    "#keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "# 当监测值不再改善时，该回调函数将中止训练.\n",
    "#当early stop被激活（如发现loss相比上一个epoch训练没有下降），则经过patience个epoch后停止训练\n",
    "#keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "        #设置训练完之后,最好的模型保存路径\n",
    "        checkpointer = ModelCheckpoint(filepath='../models/{0}/{0}_{1}sunlibo.best.h5'.format(prefix_cls,KEY), verbose=1, \n",
    "                                    save_best_only=True)\n",
    "        #训练开始,并保存训练过程的loss和acc变化\n",
    "        batch_size=8\n",
    "        g = p.keras_generator_from_array(X_train, y_train, batch_size=batch_size)\n",
    "        #X, y = next(g)\n",
    "        #fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
    "        #fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)\n",
    "\n",
    "        h = model.fit_generator(g, steps_per_epoch=len(X_train)/batch_size, epochs=30, verbose=1,\n",
    "                               callbacks=[EarlyStopping(patience=28), checkpointer], \n",
    "                              shuffle=True, \n",
    "                              class_weight=None,\n",
    "                              validation_data=(X_valid,y_valid)\n",
    "                               )\n",
    "                               \n",
    "#         h = model.fit(X_train, y_train, batch_size=16, epochs=35, \n",
    "#                      # callbacks=[EarlyStopping(patience=28), checkpointer], \n",
    "#                       shuffle=True, \n",
    "#                       validation_data=(X_valid,y_valid))\n",
    "        #是指取最后一个epochs训练得到的模型做一次整个验证集的准确率测试\n",
    "        #score = model.evaluate(X_valid,y_valid,batch_size=32,verbose=0)\n",
    "        #print ('{0}_{1}验证平均accuracy:{2}'.format(prefix_cls,KEY,score[1]))\n",
    "#         plt.figure(figsize=(10, 4))\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.plot(h.history['loss'])\n",
    "#         plt.plot(h.history['val_loss'])\n",
    "#         plt.legend(['loss', 'val_loss'])\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.title('{0}_{1}_loss'.format(prefix_cls, KEY))\n",
    "        \n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.plot(h.history['acc'])\n",
    "#         plt.plot(h.history['val_acc'])\n",
    "#         plt.legend(['acc', 'val_acc'])\n",
    "#         plt.ylabel('acc')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.title('{0}_{1}_accuracy'.format(prefix_cls, KEY))\n",
    "#         #保存训练损失和准确率变化的图像\n",
    "#         plt.savefig('../models/{0}/{0}_{1}sunlibo.png'.format(prefix_cls, KEY),bbox_inches='tight')\n",
    "        \n",
    "#         #print(\"训练集下,取一个大batch,{0}在模型{1}下的loss,accuracy={2}:\".format(prefix_cls,KEY,model.evaluate(X_train, y_train, batch_size=256)))\n",
    "#         #print(\"验证集下,取一个大batch,{0}在模型{1}下的loss,accuracy={2}:\".format(prefix_cls,KEY,model.evaluate(X_valid, y_valid, batch_size=256)))\n",
    "#         for valacc in h.history['val_acc']:\n",
    "#             if valacc > 83:\n",
    "#                 fai_result.append['{0}_{1}'.format(prefix_cls, KEY)]\n",
    "    \n",
    "        #测试集上预测并输出结果\n",
    "        df_test = pd.read_csv('../test/Tests/question.csv', header=None)\n",
    "        df_test.columns = ['image_id', 'class', 'x']\n",
    "        del df_test['x']\n",
    "        \n",
    "        df_load = df_test[(df_test['class'] == cur_class)].copy()\n",
    "        df_load.reset_index(inplace=True)\n",
    "        del df_load['index']\n",
    "        \n",
    "        n = len(df_load)\n",
    "        X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "\n",
    "        for i in range(n):\n",
    "            X_test[i] = cv2.resize(cv2.imread('../test/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "        test_np = model.predict(X_test, batch_size=256)\n",
    "        result = []\n",
    "        for i, row in df_load.iterrows():\n",
    "            tmp_list = test_np[i]\n",
    "            tmp_result = ''\n",
    "            for tmp_ret in tmp_list:\n",
    "                tmp_result += '{:.6f};'.format(tmp_ret)\n",
    "\n",
    "            result.append(tmp_result[:-1])\n",
    "\n",
    "        df_load['result'] = result     \n",
    "        df_load.to_csv('../result/{1}/{0}_{1}sunlibo.csv'.format(prefix_cls, KEY), header=None, index=False)\n",
    "        print(fai_result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-11T08:41:19.290Z"
    }
   },
   "outputs": [],
   "source": [
    "print(fai_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
