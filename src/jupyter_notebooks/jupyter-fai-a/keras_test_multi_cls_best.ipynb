{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras import initializers\n",
    "from keras.applications import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "MODELS = {\"InceptionResNetV2\":InceptionResNetV2}\n",
    "\n",
    "classes = ['coat_length_labels','collar_design_labels', 'lapel_design_labels',\n",
    "           'neck_design_labels','neckline_design_labels',\n",
    "           'pant_length_labels', 'skirt_length_labels', \n",
    "           'sleeve_length_labels']    \n",
    "\n",
    "label_count = {'coat_length_labels':8,\n",
    "               'collar_design_labels':5, \n",
    "               'lapel_design_labels':5,\n",
    "               'neck_design_labels':5,\n",
    "               'neckline_design_labels':10,\n",
    "               'pant_length_labels':6, \n",
    "               'skirt_length_labels':6, \n",
    "               'sleeve_length_labels':9}\n",
    "\n",
    "fai_result = []\n",
    "#####################\n",
    "width = 299\n",
    "#####################\n",
    "version = 'multi_cls'\n",
    "#分配每个类读入内存的表格,用dict索引\n",
    "df_train = {}\n",
    "df_load = {}\n",
    "\n",
    "#分配每个类的图像数据和标签内存,用dict索引\n",
    "#X = {}\n",
    "#y = {}\n",
    "\n",
    "#for cur_class in classes:\n",
    "    #df_train[cur_class] = pd.read_csv('../train/Annotations/{0}.csv'.format(cur_class), header=None)\n",
    "    \n",
    "    #X[cur_class] = np.zeros((len(df_train[cur_class]), width, width, 3), dtype=np.uint8)\n",
    "    #y[cur_class] = np.zeros((len(df_train[cur_class]), label_count[cur_class]), dtype=np.uint8)\n",
    "    \n",
    "    #df_train[cur_class].columns = ['image_id', 'class', 'label']\n",
    "    #df_load[cur_class] = df_train[cur_class].copy()\n",
    "    #df_load[cur_class].reset_index(inplace=True)\n",
    "    #del df_load[cur_class]['index']\n",
    "    #样本总数 \n",
    "    #print(\"各类样本总数{0}:{1}\".format(cur_class,len(df_load[cur_class])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89683/89683 [13:49<00:00, 108.15it/s]\n",
      "  0%|          | 8/89683 [00:00<19:15, 77.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像已载入内存,开始载入转换的标签..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89683/89683 [07:27<00:00, 200.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入转换的标签完毕,开始网络构建和训练..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../train/Annotations/train.csv', header=None)\n",
    "df.columns = ['image_id', 'class', 'label']\n",
    "dfl = df.copy()\n",
    "dfl.reset_index(inplace=True)\n",
    "del dfl['index']\n",
    "nn = len(dfl)\n",
    "XX = np.zeros((nn, width, width, 3), dtype=np.uint8)\n",
    "yy = [np.zeros((nn, label_count[x])) for x in label_count.keys()]\n",
    "\n",
    "for i in tqdm(range(nn)):\n",
    "    #n_class = len(df_load['label'][0])\n",
    "    #if len(tmp_label) == label_count[df_load['class'][i]]:\n",
    "    XX[i] = cv2.resize(cv2.imread('../train/{0}'.format(dfl['image_id'][i])), (width, width))\n",
    "print(\"图像已载入内存,开始载入转换的标签..\")    \n",
    "for i in tqdm(range(nn)):   \n",
    "    tmp_label = dfl['label'][i]\n",
    "    yy = [np.zeros((nn, label_count[x])) for x in label_count.keys()]\n",
    "    if dfl['class'][i] == 'coat_length_labels':\n",
    "        yy[0][i][tmp_label.find('y')] = 1   \n",
    "    elif dfl['class'][i] == 'collar_design_labels':\n",
    "        yy[1][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'lapel_design_labels':\n",
    "        yy[2][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'neck_design_labels':\n",
    "        yy[3][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'neckline_design_labels':\n",
    "        yy[4][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'pant_length_labels':\n",
    "        yy[5][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    elif dfl['class'][i] == 'skirt_length_labels':\n",
    "        yy[6][i][tmp_label.find('y')] = 1\n",
    "            \n",
    "    else:\n",
    "        yy[7][i][tmp_label.find('y')] = 1\n",
    "print(\"载入转换的标签完毕,开始网络构建和训练..\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置完毕,开始网络训练,正在训练中...\n",
      "Epoch 1/5\n",
      "89683/89683 [==============================] - 2446s 27ms/step - loss: 2.3849e-05 - coat_length_labels_loss: 0.0000e+00 - collar_design_labels_loss: 0.0000e+00 - lapel_design_labels_loss: 0.0000e+00 - neck_design_labels_loss: 0.0000e+00 - neckline_design_labels_loss: 0.0000e+00 - pant_length_labels_loss: 0.0000e+00 - skirt_length_labels_loss: 2.3849e-05 - sleeve_length_labels_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "89683/89683 [==============================] - 2405s 27ms/step - loss: 2.3927e-05 - coat_length_labels_loss: 0.0000e+00 - collar_design_labels_loss: 0.0000e+00 - lapel_design_labels_loss: 0.0000e+00 - neck_design_labels_loss: 0.0000e+00 - neckline_design_labels_loss: 0.0000e+00 - pant_length_labels_loss: 0.0000e+00 - skirt_length_labels_loss: 2.3927e-05 - sleeve_length_labels_loss: 0.0000e+00\n",
      "Epoch 3/5\n",
      "89683/89683 [==============================] - 2395s 27ms/step - loss: 2.1933e-05 - coat_length_labels_loss: 0.0000e+00 - collar_design_labels_loss: 0.0000e+00 - lapel_design_labels_loss: 0.0000e+00 - neck_design_labels_loss: 0.0000e+00 - neckline_design_labels_loss: 0.0000e+00 - pant_length_labels_loss: 0.0000e+00 - skirt_length_labels_loss: 2.1933e-05 - sleeve_length_labels_loss: 0.0000e+00\n",
      "Epoch 4/5\n",
      "89683/89683 [==============================] - 2414s 27ms/step - loss: 1.5884e-05 - coat_length_labels_loss: 0.0000e+00 - collar_design_labels_loss: 0.0000e+00 - lapel_design_labels_loss: 0.0000e+00 - neck_design_labels_loss: 0.0000e+00 - neckline_design_labels_loss: 0.0000e+00 - pant_length_labels_loss: 0.0000e+00 - skirt_length_labels_loss: 1.5884e-05 - sleeve_length_labels_loss: 0.0000e+00\n",
      "Epoch 5/5\n",
      "89683/89683 [==============================] - 2406s 27ms/step - loss: 1.4390e-05 - coat_length_labels_loss: 0.0000e+00 - collar_design_labels_loss: 0.0000e+00 - lapel_design_labels_loss: 0.0000e+00 - neck_design_labels_loss: 0.0000e+00 - neckline_design_labels_loss: 0.0000e+00 - pant_length_labels_loss: 0.0000e+00 - skirt_length_labels_loss: 1.4390e-05 - sleeve_length_labels_loss: 0.0000e+00\n",
      "训练完毕!\n",
      "开始保存模型\n"
     ]
    }
   ],
   "source": [
    "for KEY, MODLE in MODELS.items():\n",
    "    #为299*299,设置如下\n",
    "    ppreprocess = preprocess_input\n",
    "    if KEY in [\"InceptionV3\",\"Xception\", \"InceptionResNetV2\"]:\n",
    "        width = 299\n",
    "    elif KEY == \"NASNetLarge\":\n",
    "        width = 331\n",
    "    else:\n",
    "        width = 224\n",
    "        ppreprocess = imagenet_utils.preprocess_input \n",
    "    #定义模型\n",
    "    #定义要finetune的模型结构\n",
    "    cnn_model = MODLE(include_top=False, input_shape=(width, width, 3), weights='imagenet',pooling='avg')\n",
    "    #输入模型网络的图片shape,如x = Input(shape=(256, 256, 3))\n",
    "    inputs = Input((width, width, 3))#inputs = Input(shape=(784,))\n",
    "    x = inputs\n",
    "    #装入内存图片的预处理操作\n",
    "    x = Lambda(ppreprocess, name='preprocessing')(x)\n",
    "    #构建网络各模块逻辑连接\n",
    "    x = cnn_model(x)\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    ######下面是新加的层########\n",
    "    #因为设置了全局均值采样,所以没有flatten\n",
    "    x = Dropout(0.5)(x)#其他形式:model.add(Dropout(0.25))\n",
    "    #x = Flatten(name='flatten')(x)#其他形式:model.add(Flatten()),out = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dense(512, activation='relu', kernel_initializer=initializers.he_uniform(seed=None),name='fc2')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # n_class为对应属性的分类个数predictions[0]~predictions[8]\n",
    "    predictions = [Dense(count, activation='softmax', name=name)(x) for name, count in label_count.items()]\n",
    "\n",
    "    #将构建的模型网络实例化\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "        \n",
    "    #设置权参优化方法\n",
    "    #optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    optimizer = SGD(lr=0.01, decay=0.01/40, momentum=0.9, nesterov=True)\n",
    "    #optimizer = optimizers.Adam(lr=1e-4)\n",
    "    #optimizer = Adam(lr=0.0001)\n",
    "    #optimizer = 'rmsprop'\n",
    "        \n",
    "    #设置多GPU数据并行训练\n",
    "    #多GPU训练,因为keras设计的自动保存最好模型,但是多GPU训练,其save()就没法用了,需定义各保存函数\n",
    "    #model = multi_gpu_model(model, 2)  \n",
    "        \n",
    "    #所构建模型的编译,其中loss和metrics都可自定义,metrics=['accuracy',func自定义评价]\n",
    "    model.compile(optimizer=optimizer,loss='categorical_crossentropy')\n",
    "\n",
    "    # Callback实现学习率调整方案和保存最好模型即EarlyStopping\n",
    "    #schedule = Step([20], [1e-4, 1e-6])\n",
    "    #history = model.fit(X_train, Y_train,\n",
    "    #                    batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test,Y_test),\n",
    "    #                    callbacks=[schedule, keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "    #当监测值不再改善时，该回调函数将中止训练.\n",
    "    #当early stop被激活（如发现loss相比上一个epoch训练没有下降），则经过patience个epoch后停止训练\n",
    "    #keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "    #设置训练完之后,最好的模型保存路径,可设置监控准确率而不是监控loss的变化,如monitor='val_acc'\n",
    "    #checkpointer = ModelCheckpoint(filepath='../models/{0}/{0}_{1}_{2}.best.h5'.format(prefix, KEY, version), verbose=1, save_best_only=True)\n",
    "    #训练开始,并保存训练过程的loss和acc变化,h代表history\n",
    "    #model.fit([headline_data, additional_data], [labels, labels],\n",
    "          #epochs=50, batch_size=32)\n",
    "    print(\"配置完毕,开始网络训练,正在训练中...\")\n",
    "    h = model.fit(XX, yy, batch_size=16, epochs=5, shuffle=True)\n",
    "    \n",
    "    print(\"训练完毕!\")\n",
    "    #保存模型\n",
    "    print(\"开始保存模型\")\n",
    "    model.save_weights('../multi_model.h5')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练完毕!开始网络模型在测试集测试,数据装入及测试结果保存输出...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10080/10080 [00:01<00:00, 8358.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存测试后的结果文件...\n",
      "Complete!!!\n"
     ]
    }
   ],
   "source": [
    "print(\"训练完毕!开始网络模型在测试集测试,数据装入及测试结果保存输出...\")   \n",
    "#在测试集上预测并保存结果\n",
    "df_test = pd.read_csv('../test/Tests/question.csv', header=None)\n",
    "#定义各列名称\n",
    "df_test.columns = ['image_id', 'class', 'x']\n",
    "del df_test['x']\n",
    "df_load = df_test.copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "        \n",
    "n = len(df_load)\n",
    "X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "#读取测试集图像到内存并resize\n",
    "for i in range(n):\n",
    "    X_test[i] = cv2.resize(cv2.imread('../test/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "#以batch_size处理的速度遍历测试集,处理并预测\n",
    "test_np = model.predict(X_test, batch_size=256)\n",
    "\n",
    "nn = len(df_load)\n",
    "result = []\n",
    "for i in tqdm(range(nn)):\n",
    "    tmp_result = ''\n",
    "    if df_load['class'][i] == 'coat_length_labels':\n",
    "        tmp_listdd = test_np[0][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "\n",
    "    elif df_load['class'][i] == 'collar_design_labels':\n",
    "        tmp_listdd = test_np[1][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "\n",
    "    elif df_load['class'][i] == 'lapel_design_labels':\n",
    "        tmp_listdd = test_np[2][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "\n",
    "    elif df_load['class'][i] == 'neck_design_labels':\n",
    "        \n",
    "        tmp_listdd = test_np[3][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "\n",
    "\n",
    "    elif df_load['class'][i] == 'neckline_design_labels':\n",
    "        tmp_listdd = test_np[4][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "\n",
    "    elif df_load['class'][i] == 'pant_length_labels':\n",
    "        tmp_listdd = test_np[5][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "\n",
    "    elif df_load['class'][i] == 'skirt_length_labels':\n",
    "        tmp_listdd = test_np[6][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "\n",
    "    else:\n",
    "        tmp_listdd = test_np[7][i]\n",
    "        for tmp_ret in tmp_listdd:\n",
    "            tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        result.append(tmp_result[:-1])\n",
    "print(\"保存测试后的结果文件...\")\n",
    "#预测结果导入内存表格的result列\n",
    "df_load['result'] = result     \n",
    "df_load.to_csv('../result/{0}_{1}.csv'.format(KEY, version), header=None, index=False)\n",
    "print(\"Complete!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
