{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T13:43:28.308374Z",
     "start_time": "2018-04-06T13:43:28.303885Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#当采用交叉熵,在train函数中:\n",
    "#_,prediction = torch.max(F.softmax(prediction.data), 1),_代表的是概率值\n",
    "#_,prediction = torch.max(prediction.data, 1),_代表的不是是概率值\n",
    "#注意outputs = model(inputs)的outputs为Variable,而用于torch.max中的应为Tensor\n",
    "#_, preds = torch.max(F.softmax(outputs.data), 1)\n",
    "#局部微调:\n",
    "#model = torchvision.models.resnet18(pretrained=True)\n",
    "#for param in model.parameters():\n",
    "    #param.requires_grad = False\n",
    "#model.fc = nn.Linear(512, 100)\n",
    "#a = torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T13:43:28.416285Z",
     "start_time": "2018-04-06T13:43:28.311362Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: 孙立波 created on 2018-04-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T13:43:29.913332Z",
     "start_time": "2018-04-06T13:43:28.418548Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################环境设置#######################\n",
    "import torch\n",
    "from torch.autograd import Variable ## torch中自动计算梯度模块\n",
    "import torch.nn as nn # 神经网络模块\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F  #神经网络模块中的常用功能 \n",
    "import torch.multiprocessing as mp\n",
    "from torch import optim\n",
    "from torch.optim import *\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets, models\n",
    "from torchvision.models import *\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()   # interactive mode\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#显示中文字体设置\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Droid Sans Fallback\"]\n",
    "plt.rcParams['axes.unicode_minus'] = False #为了正常显示是\"-\"减号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T13:43:29.928871Z",
     "start_time": "2018-04-06T13:43:29.916142Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################## 准备 #######################\n",
    "# MODELS = {\"resnet18\":resnet18,\"resnet34\":resnet34,\"resnet50\":resnet50,\n",
    "#           \"resnet101\":resnet101,\"resnet152\":resnet152,\n",
    "#           \"inception_v3\":inception_v3,\n",
    "#           \"densenet161\":densenet161,\"densenet121\":densenet121,\"densenet169\":densenet169,\"densenet201\":densenet201,\n",
    "#           \"alexnet\":alexnet,\"vgg11\":vgg11,\"vgg11_bn\":vgg11_bn,\"vgg13\":vgg13,\n",
    "#           \"vgg13_bn\":vgg13_bn,\"vgg16\":vgg16,\"vgg16_bn\":vgg16_bn,\"vgg19\":vgg19,\n",
    "#           \"vgg19_bn\":vgg19_bn}\n",
    "#MODELS = {\"resnet18\":resnet18,\"resnet152\":resnet152,\"resnet50\":resnet50,\"inception_v3\":inception_v3,\"densenet161\":densenet161}\n",
    "MODELS = {\"resnet50\":resnet50,\"resnet152\":resnet152} #注:\"inception_v3\":inception_v3的输入图像需是width=299,densenet161最后一层叫classifier,而不叫fc\n",
    "OPTIMIZERS = {\"SGD\":SGD,\"ASGD\":ASGD,\"Adam\":Adam,\"Adagrad\":Adagrad}\n",
    "# classes = [ 'collar_design_labels','neckline_design_labels','skirt_length_labels', \n",
    "#             'sleeve_length_labels', 'neck_design_labels', 'lapel_design_labels', \n",
    "#             'pant_length_labels','coat_length_labels']   \n",
    "#classes = ['collar_design_labels', 'neckline_design_labels', 'neck_design_labels'] \n",
    "classes = ['collar_design_labels'] \n",
    "label_count = {'coat_length_labels':8,\n",
    "               'collar_design_labels':5, \n",
    "               'lapel_design_labels':5,\n",
    "               'neck_design_labels':5,\n",
    "               'neckline_design_labels':10,\n",
    "               'pant_length_labels':6, \n",
    "               'skirt_length_labels':6, \n",
    "               'sleeve_length_labels':9}\n",
    "\n",
    "attrs_cls_label_map = {\n",
    "    'skirt_length_labels':['群不可见Invisible', '短群Short', '及膝群Knee', '旗袍裙群Midi', '及脚群Ankle', '接地群Floor'],\n",
    "    'coat_length_labels': ['衣不可见Invisible','高腰衣HighWaistLength','常规衣RegularLength','长衣LongLength','加长衣MicroLength',\n",
    "                           '及膝衣Knee Length','旗袍衣MidiLength','及地衣Ankle&FloorLength'],\n",
    "    'collar_design_labels': ['衣领不可见Invisible','衬衫领ShirtCollar','彼得潘女士小圆领PeterPan','清道夫领PuritanCollar','螺纹领RibCollar'],\n",
    "    'lapel_design_labels':['翻领不可见Invisible','缺口领Notched','无领Collarless','披肩围巾式领ShawlCollar','大号披肩围巾式领PlusSizeShawl'],\n",
    "    'neck_design_labels':['脖颈不可见Invisible','长高领TurtleNeck', '荷叶半高领RuffleSemi-HighCollar','低圆领LowTurtleNeck','翻领Draped Collar'],\n",
    "    'neckline_design_labels':['颈领线不可见Invisible','无肩带领StraplessNeck','深V领DeepVNeckline', '直领StraightNeck', 'V领VNeckline', \n",
    "                              '方领SquareNeckline', '出肩领OffShoulder', '圆领RoundNeckline', '桃形领SweatHeartNeck', '单肩领OneShoulderNeckline'],\n",
    "    'pant_length_labels':[ '裤不可见Invisible', '短裤ShortPant', '中裤Mid Length', '7分裤3/4Length', '9分裤CroppedPant', '长裤FullLength'],\n",
    "    'sleeve_length_labels':['袖不可见Invisible', '无袖Sleeveless', '杯袖CupSleeves', '短袖ShortSleeves', '肘中袖ElbowSleeves',\n",
    "                            '7分袖Sleeves', '及腕9分袖WristLength', '长袖LongSleeves', '超长袖ExtraLongSleeves']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T13:43:30.162033Z",
     "start_time": "2018-04-06T13:43:29.931084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################## 参数设置 #######################\n",
    "\n",
    "#参数设置\n",
    "\n",
    "#设置可见的GPU数,注意不是并行训练的设置\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "#若gpu可用则返回True\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "        #sgd = SGD(lr=0.01, decay=0.01/45, momentum=0.9, nesterov=True)\n",
    "        #adam = optimizers.Adam(lr=1e-4)\n",
    "        #optimizer=sgd(lr=0.001, momentum=0.9, nesterov=True))\n",
    "        #adam = Adam(lr=0.0001)\n",
    "#保存文件后缀,即月份和日为版本尾号\n",
    "#version = \"\"\n",
    "version = '0406fainet2'\n",
    "image_width = 224\n",
    "epochs_num = 50\n",
    "scheduler_step_size = 10#设置含参变量的学习率变化，为多少个epoch做一次步进的衰减\n",
    "learning_rate = 0.001\n",
    "split_ratio = 0.2\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T13:43:32.534565Z",
     "start_time": "2018-04-06T13:43:30.164961Z"
    }
   },
   "outputs": [],
   "source": [
    "########################### 定义数据集类和预处理类及操作和数据集实例化测试 #######################\n",
    "\n",
    "######################################################################################\n",
    "#Data augmentation and normalization for training,Just normalization for validation\n",
    "\n",
    "#Transforms on PIL Image\n",
    "#过时class torchvision.transforms.Scale(size, interpolation=2) #按照规定的尺寸重新调节PIL.Image\n",
    "#class torchvision.transforms.Resize(size, interpolation=2)\n",
    "#class torchvision.transforms.CenterCrop(size) #将给定的PIL.Image进行中心切割，得到给定的size，size可以是tuple，(target_height, target_width)。size也可以是一个Integer，在这种情况下，切出来的图片的形状是正方形\n",
    "#class torchvision.transforms.RandomCrop(size, padding=0) #切割中心点的位置随机选取。size可以是tuple也可以是Integer。\n",
    "#class torchvision.transforms.RandomHorizontalFlip(p=0.5) #随机水平翻转给定的PIL.Image,概率为0.5。即：一半的概率翻转，一半的概率不翻转。\n",
    "#过时class torchvision.transforms.RandomSizedCrop(size, interpolation=2) #先将给定的PIL.Image随机切，然后再resize成给定的size大小。\n",
    "#class torchvision.transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)\n",
    "#class torchvision.transforms.FiveCrop(size) #可能不匹配batchsize，见官网。Crop the given PIL Image into four corners and the central crop\n",
    "#class torchvision.transforms.TenCrop(size, vertical_flip=False)\n",
    "#class torchvision.transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0) #Randomly change the brightness, contrast and saturation of an image.\n",
    "#class torchvision.transforms.RandomRotation(degrees, resample=False, expand=False, center=None)\n",
    "#class torchvision.transforms.RandomAffine(degrees, translate=None, scale=None, shear=None, resample=False, fillcolor=0)\n",
    "\n",
    "#Transforms on torch.*Tensor\n",
    "#class torchvision.transforms.Normalize(mean, std) #给定均值：(R,G,B) 方差：（R，G，B），将会把Tensor的每个通道矩阵值规范化到正态分布上。即：Normalized_image=(image-mean)/std。\n",
    "\n",
    "#Conversion Transforms\n",
    "#class torchvision.transforms.ToTensor #Convert a PIL Image or numpy.ndarray to tensor.如把一个取值范围是[0,255]的PIL.Image或者shape为(H,W,C)的numpy.ndarray，转换成形状为[C,H,W]，取值范围是[0.0,1.0]的torch.FloadTensor\n",
    "#class torchvision.transforms.ToPILImage(mode=None)\n",
    "\n",
    "#class torchvision.transforms.Lambda(lambd) #使用转换器\n",
    "#Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops]))\n",
    "\n",
    "#应加入的数据增强：对fai一定不要用transforms.RandomCrop(size, padding=0)\n",
    "#transforms.Resize(image_width, interpolation=2) #一般放缩到224*224，并保持边长比不变\n",
    "#transforms.RandomHorizontalFlip(p=0.65) #这个很有用！！！\n",
    "#transforms.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.2, hue=0.2) #是随机的，赋值为增益因子\n",
    "#transforms.RandomRotation(20, resample=False, expand=False, center=None)\n",
    "\n",
    "#可能轻微的影响transforms.RandomResizedCrop(image_width, scale=(0.95, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)\n",
    "#可能会有用，可用于测试阶段transforms.CenterCrop((224,180))，如：transforms.CenterCrop(256，224)#注意不是随机裁剪，即高不变，裁剪的宽变化\n",
    "\n",
    "################################################################################\n",
    "#注：定义的dataset经自定义的transform或库自带的基于PIL的数据变换返回的图像和label都应是Tensor形式，而用库自带的变换，需用PIL读取图像！\n",
    "\n",
    "#定义数据预处理\n",
    "\n",
    "#######################transforms.RandomRotation(10)#改变10度\n",
    "        ###############################transforms.ColorJitter(0.05, 0.05, 0.05, 0.05)#微小抖动\n",
    "fai_data_transforms = {\n",
    "                    'train': transforms.Compose([\n",
    "                        transforms.Resize(image_width, interpolation=2),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                        transforms.RandomRotation(10, resample=False, expand=False, center=None),\n",
    "                        transforms.RandomResizedCrop(image_width, scale=(0.95, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2),\n",
    "                        \n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                    ]),\n",
    "                    'val': transforms.Compose([\n",
    "                        #transforms.Resize(256),\n",
    "                        #transforms.CenterCrop(256,224),\n",
    "                        transforms.Resize(image_width, interpolation=2),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                    ]),\n",
    "                    'test': transforms.Compose([\n",
    "                        #transforms.Resize(256),\n",
    "                        #transforms.CenterCrop(256,224),\n",
    "                        transforms.Resize(image_width, interpolation=2),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                    ])\n",
    "}\n",
    "\n",
    "#定义数据集\n",
    "#当变换中含有 transforms.ToTensor(),处理后为RGB CHW 0-1.0数据，当含有transforms.Normalize()会返回一个分布在(x-mean)/std,这时值的范围就不是0-1.0了\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB').resize((224,224),Image.NEAREST)\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)\n",
    "#定义数据集\n",
    "class FaiTrainDataset(Dataset):\n",
    "    \"\"\"FaiTrainDataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_csv_path_and_file, train_val_images_root_dir, train =True, split_ratio=0.2,transform=None,target_transform=None,loader=default_loader):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(train_csv_path_and_file)\n",
    "        #self.df_load = df.sample(frac=1).reset_index(drop=True)\n",
    "        self.df_load = self.df.copy()\n",
    "        #df.iloc[np.random.permutation(len(df))]\n",
    "        self.split_ratio = split_ratio\n",
    "        self.cut_idx = int(len(self.df_load)-round(len(self.df_load)*self.split_ratio))#int(round(0.1 * self.df_load.shape[0]))\n",
    "        self.df_train= self.df_load.iloc[:self.cut_idx]\n",
    "        self.df_val = self.df_load.iloc[self.cut_idx:]\n",
    "        \n",
    "        self.df_train_load = self.df_train.copy()\n",
    "        self.df_val_load = self.df_val.copy()\n",
    "        \n",
    "        self.df_train_load.columns = ['image_id', 'class', 'label']\n",
    "        self.df_val_load.columns = ['image_id', 'class', 'label']\n",
    "        \n",
    "        self.df_train_load.reset_index(inplace= True,drop=True)\n",
    "        self.df_val_load.reset_index(inplace= True,drop=True)\n",
    "        \n",
    "        self.train_images = self.df_train_load['image_id'].tolist()\n",
    "        self.train_labels = self.df_train_load['label'].tolist()\n",
    "        \n",
    "        self.val_images = self.df_val_load['image_id'].tolist()\n",
    "        self.val_labels = self.df_val_load['label'].tolist()\n",
    "        \n",
    "        n1=len(self.df_train_load)\n",
    "        n2=len(self.df_val_load)\n",
    "        \n",
    "        #不用转化为one-hot，根据所用的交叉熵形式\n",
    "        #self.train_y = np.zeros((n1, label_count[self.df_train_load['class'][0]]), dtype=np.uint8)\n",
    "        #self.val_y = np.zeros((n2, label_count[self.df_val_load['class'][0]]), dtype=np.uint8)\n",
    "        self.train_y = np.zeros(n1, dtype=np.uint8)\n",
    "        self.val_y = np.zeros(n2, dtype=np.uint8)\n",
    "        \n",
    "        for i in range(n1):\n",
    "            tmp_label1=self.train_labels[i]\n",
    "            self.train_y[i]=tmp_label1.find('y')\n",
    "        for j in range(n2):\n",
    "            tmp_label2=self.val_labels[j]\n",
    "            self.val_y[j]=tmp_label2.find('y')\n",
    "        self.train_data = list(zip(self.train_images,self.train_y))\n",
    "        self.val_data = list(zip(self.val_images,self.val_y))\n",
    "        #print(\"训练集：batch化需要的元组样例是{0}：\".format(self.train_data[0]))\n",
    "        #print(\"验证集：batch化需要的元组样例是{0}：\".format(self.val_data[0]))\n",
    "        \n",
    "        self.train_val_images_root_dir = train_val_images_root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train == True:\n",
    "            return len(self.df_train_load)\n",
    "        else:\n",
    "            return len(self.df_val_load)\n",
    "\n",
    "    def __getitem__(self, index): #最终返回的是Tensor\n",
    "        if self.train == True:\n",
    "            train_image_path, train_label = self.train_data[index]\n",
    "            train_img_name = os.path.join(self.train_val_images_root_dir,train_image_path)\n",
    "            #image = io.imread(img_name) #用的skimage.io,读入为uint8，RGB，HWc图像\n",
    "            train_img = self.loader(train_img_name)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                train_img = self.transform(train_img) #处理后为RGB CHW ，个位整数的数据\n",
    "            if self.target_transform is not None:\n",
    "                train_label = self.target_transform(train_label)\n",
    "            return train_img,train_label\n",
    "        else:\n",
    "            val_image_path, val_label = self.val_data[index]\n",
    "            val_img_name = os.path.join(self.train_val_images_root_dir,val_image_path)\n",
    "            #image = io.imread(img_name) #用的skimage.io,读入为uint8，RGB，HWc图像\n",
    "            val_img = self.loader(val_img_name)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                val_img = self.transform(val_img) ##处理后为RGB CHW ，个位整数的数据\n",
    "            if self.target_transform is not None:\n",
    "                val_label = self.target_transform(val_label)\n",
    "            return val_img,val_label #返回值是Tensor\n",
    "            \n",
    "#定义测试数据集\n",
    "class FaiTestDataset(Dataset):\n",
    "    \"\"\"FaiTestDataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, test_csv_path_and_file, test_images_root_dir, attr, transform=None,target_transform=None,loader=default_loader):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "       \n",
    "        self.df_test = pd.read_csv(test_csv_path_and_file)\n",
    "        #定义各列名称\n",
    "        self.df_test.columns = ['image_id', 'class', 'x']\n",
    "        del self.df_test['x']\n",
    "        self.attr = attr\n",
    "        \n",
    "        self.df_test_load = self.df_test[(self.df_test['class'] == self.attr)].copy()\n",
    "        self.df_test_load.reset_index(inplace= True,drop= True)\n",
    "        \n",
    "        self.test_images = self.df_test_load['image_id'].tolist()\n",
    "        #n=len(self.df_test_load)\n",
    "        #self.test_y = np.zeros((n, label_count[self.attr]), dtype=np.uint8)\n",
    "        #self.test_data = list(zip(self.test_images,self.test_y))\n",
    "        self.test_data = self.test_images\n",
    "        #print(\"测试集（不含label）：batch化需要的元组样例是{0}：\".format(self.test_data[0]))\n",
    "    \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.test_images_root_dir = test_images_root_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_test_load)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_path = self.test_data[index]\n",
    "        test_img_name = os.path.join(self.test_images_root_dir,test_path)\n",
    "        #test_image = io.imread(test_img_name) 只能用PIL读图像，因为系统要求\n",
    "        test_img = self.loader(test_img_name)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            test_img = self.transform(test_img) #处理后为RGB CHW ，个位整数的数据\n",
    "\n",
    "        return test_img #返回值为Tensor\n",
    "\n",
    "################################################## 对定义的数据集做测试  以classes[0]属性为例 ####################\n",
    "#定义的dataset经自定义的transform或库自带的基于PIL的数据变换返回的图像和label都应是Tensor形式，而用库自带的变换，需用PIL读取图像！\n",
    "#测试训练，验证和测试数据上的数据增强\n",
    "fai_train_dataset = FaiTrainDataset(train_csv_path_and_file='../train/Annotations/{0}.csv'.format(classes[0]),\n",
    "                                   train_val_images_root_dir='../train/',\n",
    "                                   train =True, split_ratio=split_ratio,\n",
    "                                   transform = fai_data_transforms['train'])\n",
    "fai_val_dataset = FaiTrainDataset(train_csv_path_and_file='../train/Annotations/{0}.csv'.format(classes[0]),\n",
    "                                   train_val_images_root_dir='../train/',\n",
    "                                   train =False, split_ratio=split_ratio,\n",
    "                                   transform = fai_data_transforms['val'])\n",
    "\n",
    "image_datasets = {'train': fai_train_dataset, 'val':fai_val_dataset}\n",
    "\n",
    "#关于训练验证集\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_lengths = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "#关于测试集\n",
    "fai_test_dataset = FaiTestDataset(test_csv_path_and_file='../test/Tests/question.csv',\n",
    "                                  test_images_root_dir='../test/',\n",
    "                                  attr =classes[0],\n",
    "                                  transform = fai_data_transforms['test'])\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(fai_test_dataset, batch_size=4,shuffle=False, num_workers=4)\n",
    "test_dataset_length = len(fai_test_dataset)\n",
    "       \n",
    "print()         \n",
    "# print(\"dataloaders['train']的一个batch输出为：\")\n",
    "# print(next(iter(dataloaders['train'])))\n",
    "# print(\"dataloaders['val']的一个batch输出为：\")\n",
    "# print(next(iter(dataloaders['val'])))\n",
    "# print(\"test_dataloader的一个batch输出为：\")\n",
    "# print(next(iter(test_dataloader)))\n",
    "\n",
    "print()\n",
    "print(\"train,val,test的一个batch输出shape分别为：\")\n",
    "train_sample1,train_sample2= next(iter(dataloaders['train']))\n",
    "print(\"train#\",'1个batch图像数据：',train_sample1.size(),'1个batch的labels：',train_sample2.size())\n",
    "val_sample1,val_sample2= next(iter(dataloaders['val']))\n",
    "print(\"val#\",'1个batch图像数据：',val_sample1.size(),'1个batch的labels：',val_sample2.size())\n",
    "test_sample1= next(iter(test_dataloader))\n",
    "print(\"test#\",'1个batch图像数据：',test_sample1.size())\n",
    "    \n",
    "print()\n",
    "\n",
    "#测试定义的数据,一个batch的数据可视化\n",
    "def fai_augment_visualize(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0)) #若用cv显示则是：inp = inp.numpy().transpose((1, 2, 0))*255 \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    #plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    # opencv\n",
    "    #img2 = data[i][0].numpy()*255\n",
    "    #img2 = img2.astype('uint8')\n",
    "    #img2 = np.transpose(img2, (1,2,0))\n",
    "    #img2=img2[:,:,::-1]#RGB->BGR\n",
    "    #cv2.imshow('img2', img2)\n",
    "    #cv2.waitKey()\n",
    "print(\"Attr:{0}.Train样本数：{1} ，Val样本数：{2}，Test样本数：{3}\".format(classes[0],len(fai_train_dataset),len(fai_val_dataset),len(fai_test_dataset)))\n",
    "#torch.utils.data.DataLoader是一个提供功能的迭代器。其中一个蛮有趣的参数是collate_fn。\n",
    "#可用collate_fn来指定如何读取一批的样本。然而，默认的collate在大部分的情况下都表现得很好。\n",
    "# Get a batch of training data\n",
    "inputs1, classes1 = next(iter(dataloaders['train']))\n",
    "inputs2, classes2 = next(iter(dataloaders['val']))\n",
    "inputs3 = next(iter(test_dataloader))\n",
    "# Make a grid from batch and visualize输出\n",
    "plt.figure(0)\n",
    "out1 = torchvision.utils.make_grid(inputs1) #为CHW，RGB 0.0-1.0图像，用plt显示需转化为HWC形式\n",
    "fai_augment_visualize(out1, title='train-augment-{0}'.format(classes[0]))\n",
    "plt.figure(1)\n",
    "out2 = torchvision.utils.make_grid(inputs2)\n",
    "fai_augment_visualize(out2, title='val-augment-{0}'.format(classes[0]))\n",
    "plt.figure(3)\n",
    "out3 = torchvision.utils.make_grid(inputs3)\n",
    "fai_augment_visualize(out3, title='test-augment-{0}'.format(classes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T13:43:32.581769Z",
     "start_time": "2018-04-06T13:43:32.538791Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################### 定义训练和测试及其他可视化函数 #######################\n",
    "#定义训练模型的具体步骤及参数设置\n",
    "def fai_train_model(model, criterion, optimizer, scheduler, batch_size,split_ratio,num_epochs,attr,model_key,version):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    #测试训练，验证和测试数据上的数据增强\n",
    "    training_fai_train_dataset = FaiTrainDataset(train_csv_path_and_file='../train/Annotations/{0}.csv'.format(attr),\n",
    "                                       train_val_images_root_dir='../train/',\n",
    "                                       train =True, split_ratio=split_ratio,\n",
    "                                       transform= fai_data_transforms['train'])\n",
    "    training_fai_val_dataset = FaiTrainDataset(train_csv_path_and_file='../train/Annotations/{0}.csv'.format(attr),\n",
    "                                       train_val_images_root_dir='../train/',\n",
    "                                       train =False, split_ratio=split_ratio,\n",
    "                                       transform= fai_data_transforms['val'])\n",
    "    training_image_datasets = {'train': training_fai_train_dataset, 'val':training_fai_val_dataset}\n",
    "\n",
    "    #关于训练验证集的封装\n",
    "    training_dataloaders = {x: torch.utils.data.DataLoader(training_image_datasets[x], batch_size=batch_size,shuffle=True, num_workers=8)\n",
    "                   for x in ['train', 'val']}\n",
    "    training_dataset_lengths = {x: len(training_image_datasets[x]) for x in ['train', 'val']}\n",
    "    print(\"摘要：Attr:{0}.Train样本数：{1} ，Val样本数：{2}\".format(attr,training_dataset_lengths['train'],training_dataset_lengths['val']))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            #每batch一次train，就val一次\n",
    "            if phase == 'train':\n",
    "                #与Optimizer类似的是，其主要功能体现在step()方法中，用于更新optimizer对象每个param_group字典的lr键的值。\n",
    "                #scheduler = torch.optim.ReduceLROnPlateau(optimizer, 'min')，这应用在函数体外\n",
    "                #scheduler.step() #\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in training_dataloaders[phase]:\n",
    "                # get the inputs(每次一个batch)\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    \n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.long().cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs,volatile=True), Variable(labels,volatile=True)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                #_, preds = torch.max(F.softmax(utputs.data), 1)\n",
    "                _, preds = torch.max(outputs.data, 1) #第一个是最大值的张量(注意此处不是概率值)，第二个是索引值\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                # 即用的总loss而不是平均loss\n",
    "                running_loss += loss.data[0] * inputs.size(0) #inputs.size(0)：每个batchsize的大小\n",
    "                running_corrects += torch.sum(preds == labels.data) #可知标签不用转化为one-hot\n",
    "               \n",
    "            epoch_loss = running_loss / training_dataset_lengths[phase]\n",
    "            epoch_acc = running_corrects / training_dataset_lengths[phase]\n",
    "            if phase == 'val':\n",
    "                scheduler.step(epoch_acc)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    #保存最好的模型\n",
    "    print(\"开始保存模型\")\n",
    "    prefix_cls = attr.split('_')[0]\n",
    "    PATH = '../models/{0}/pytorch_{0}_{1}_{2}'.format(prefix_cls, model_key, version)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    #model = 你定义的模型class封装\n",
    "    #model.load_state_dict(torch.load(PATH))\n",
    "    print(\"保存最好的模型完成\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "######这是将训练好的模型用于测试集上，输出对应属性的也测结果到csv文件\n",
    "#CPU版本的函数\n",
    "def fai_predict(predictor,attr,model_key,version): \n",
    "    fai_test_dataset = FaiTestDataset(test_csv_path_and_file='../test/Tests/question.csv',\n",
    "                                      test_images_root_dir='../test/',\n",
    "                                      attr =attr,\n",
    "                                      transform= fai_data_transforms['test'])\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(fai_test_dataset, batch_size=32,shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = predictor.cpu()\n",
    "    model.train(False)\n",
    "    model.eval() #model.train(False)  # Set model to evaluate mode\n",
    "    #len(test_dataloader)返回的是len(相应dataset)/batch_size\n",
    "    #for i_batch in tqdm(range(len(test_dataloader))):\n",
    "    #在测试集上预测并保存结果\n",
    "    df_test_load = fai_test_dataset.df_test_load\n",
    "    print(\"测试属性：Attr:{0}\".format(attr))\n",
    "    print('测试数据集的样本数为：{0},迭代器需要的迭代次数是：{1}次batchsize的迭代'.format(len(fai_test_dataset),len(test_dataloader)))\n",
    "    \n",
    "    result = []\n",
    "    prefix_cls = attr.split('_')[0]\n",
    "    for i,batch_x in enumerate(test_dataloader):\n",
    "        batch_x = Variable(batch_x, volatile=True)\n",
    "        out = model(batch_x)\n",
    "        out = F.softmax(out,dim=1) #把输出的正负数转到0-1之间\n",
    "        test_np=out.data.numpy()\n",
    "        \n",
    "        #tmp_list = test_np.tolist()\n",
    "        for jj in test_np:\n",
    "            \n",
    "            tmp_result = ''\n",
    "            for tmp_ret in jj:\n",
    "                tmp_result += '{:.5f};'.format(tmp_ret)\n",
    "                #不要最后一个分号\n",
    "            result.append(tmp_result[:-1])\n",
    "    \n",
    "    #预测结果导入内存表格的result列\n",
    "    df_test_load['result'] = result     \n",
    "    df_test_load.to_csv('../result/pytorch/pytorch_{0}_{1}_{2}.csv'.format(prefix_cls, model_key, version), header=None, index=False) \n",
    "    print('#######完成{0}:{1}下的测试集上的csv文件输出'.format(model_key,attr))\n",
    "        \n",
    "######这是可视化预测输出函数，用于测试集上的预测可视化，测试一个batch的输出（设置batchsize大小的是n_pictures）\n",
    "#predictor：模型分类器#attr：要测试的属性#n_pictures：要测试的图片数,最好别大于8,因为输出为1*n的形式\n",
    "#CPU+cuda版本的函数\n",
    "def fai_predict_test_data_visualize(predictor, attr, n_pictures=8,use_gpu= False):\n",
    "    fai_test_dataset = FaiTestDataset(test_csv_path_and_file='../test/Tests/question.csv',\n",
    "                                  test_images_root_dir='../test/',\n",
    "                                  attr =attr,\n",
    "                                  transform= fai_data_transforms['test'])\n",
    "    test_dataloader = torch.utils.data.DataLoader(fai_test_dataset, batch_size=n_pictures,shuffle=False, num_workers=4)\n",
    "    test_dataset_length = len(fai_test_dataset) #注：len(test_dataloader)返回的是len(相应dataset)/batch_size\n",
    "    if use_gpu:\n",
    "        model = predictor.cuda()\n",
    "        model.train(False)\n",
    "        model.eval()\n",
    "    else:\n",
    "        \n",
    "        model = predictor.cpu()\n",
    "        model.train(False)\n",
    "        model.eval()\n",
    "    # get some random training images\n",
    "    dataiter = iter(test_dataloader)\n",
    "    batch_x= dataiter.next()\n",
    "    if use_gpu:\n",
    "        batch_xx = Variable(batch_x.cuda(), volatile=True)\n",
    "    else:\n",
    "        batch_xx = Variable(batch_x,volatile=True)  \n",
    "    outputs = model(batch_xx)\n",
    "    _, predicted = torch.max(outputs.data, 1) #此时predicted为Tensor类型的索引列表\n",
    "\n",
    "    if use_gpu:\n",
    "        aa = predicted.cpu().numpy()\n",
    "    else:\n",
    "        aa = predicted.numpy()\n",
    "    fig,axes = plt.subplots(ncols=n_pictures,figsize=(4*n_pictures,4))  \n",
    "    print('{0}张图片预测得到的索引:'.format(n_pictures))\n",
    "    print(aa)\n",
    "    for i in range(n_pictures):\n",
    "        \"\"\"Imshow for Tensor.\"\"\"\n",
    "        inp = batch_x[i].numpy().transpose((1, 2, 0)) #若用cv显示则是：inp = inp.numpy().transpose((1, 2, 0))*255 \n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "        k = aa[i]\n",
    "        axes[i].set_title(\"pred-vis-{0},\\nPred:{1}\".format(attr,attrs_cls_label_map[attr][k]),color='r')  \n",
    "        axes[i].imshow(inp)\n",
    "    print('完成测试集上的一个batchsize测试!')\n",
    "    #plt.savefig('../images/{0}/pytorch_{0}_{1}_{2}.png'.format(prefix_cls, KEY, version),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T13:43:32.841609Z",
     "start_time": "2018-04-06T13:43:32.584924Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################### 迁移学习添加新层 ############################\n",
    "\n",
    "class FAINET(nn.Module): #model为需要finetune的base model,对于resnet最后两层分别为pooling和fc,此模型只去除最后一层,然后做一定的修改\n",
    "    def __init__(self, model,fai_classes_num, hidden_feature_size = 512): #,classes_num为分类数,hidden_feature_size是三层全连接间的隐藏层神经元个数,属于倒数第二层数\n",
    "\n",
    "        super(FAINET, self).__init__() \n",
    "        self.fai_base_features = nn.Sequential(*list(model.children())[:-2])\n",
    "        #self.fai_base_features = nn.Sequential(*list(model.children())[:-1])#即去除最后一层全连接层(一般是由卷积得来的2048维),*是解包操作\n",
    "        #若不让输出保证与原模型一样可用:\n",
    "        self.fai_num_ftrs = 2048 #特征图数 #\n",
    "        #self.fai_num_ftrs = model.fc.in_features #原模型的fc-Module输入维度,in_features为Linear类的输入参数\n",
    "        #下面是新增的操作\n",
    "#         self.fai_conv =nn.Sequential(\n",
    "#                         nn.Conv2d(self.fai_num_ftrs, 32, kernel_size=4, stride=1, padding=2), # in:如(bs,self.fai_num_ftrs,60,160)\n",
    "#                         nn.BatchNorm2d(32),\n",
    "#                         nn.LeakyReLU(0.2, inplace=True),     \n",
    "#                         nn.MaxPool2d(kernel_size=2),        # out:(bs,32,30,80)\n",
    "                        \n",
    "#                         nn.Conv2d(32, 64, kernel_size=4, stride=1, padding=2),\n",
    "#                         nn.BatchNorm2d(64),\n",
    "#                         nn.LeakyReLU(0.2, inplace=True),\n",
    "#                         nn.MaxPool2d(kernel_size=2),        # out:(bs,64,15,40)\n",
    "                        \n",
    "#                         nn.Conv2d(64, 64, kernel_size=3 ,stride=1, padding=1),\n",
    "#                         nn.BatchNorm2d(64),\n",
    "#                         nn.LeakyReLU(0.2, inplace=True),     \n",
    "#                         nn.MaxPool2d(kernel_size=2)         # out:(bs,64,7,20)\n",
    "#                     )\n",
    "        self.fai_end_classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.fai_num_ftrs),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.fai_num_ftrs, hidden_feature_size),\n",
    "            nn.BatchNorm1d(hidden_feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_feature_size, fai_classes_num)\n",
    "            #在次加入softmax则部署模型时输出的是概率值,不过也可以不加,在预测的时候加入也可以做转化,影响不大\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fai_base_features(x)\n",
    "        #加入自定义的卷积层\n",
    "        #x = self.fai_conv(x)\n",
    "        #加入全局池化\n",
    "        x = F.avg_pool2d(x, kernel_size=x.size()[2:]) #加全局均值采样得到的是batch-size*特征图的个数\n",
    "        #其实若加入了全局卷积池化就不用展平操作了\n",
    "        x = x.view(x.size(0), -1) #相当于numpy的reshape和keras的Flatten层,将二维压成一维\n",
    "        x = self.fai_end_classifier(x)\n",
    "        return x\n",
    "    \n",
    "        #x = Dropout(0.5)(x)\n",
    "        #x = Flatten(name='flatten')(x)\n",
    "        #x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "        # n_class为对应属性的分类个数\n",
    "        #x = Dense(512, activation='relu', kernel_initializer=initializers.he_uniform(seed=None),name='fc2')(x)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        #x = Dense(n_class, activation='softmax', name='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T16:24:14.712176Z",
     "start_time": "2018-04-06T13:43:32.844448Z"
    }
   },
   "outputs": [],
   "source": [
    "################################### 实例化训练和测试 ############################\n",
    "#加载预训练模型并重写全连接层。\n",
    "\n",
    "#state_dict = torch.utils.model_zoo.load_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth')\n",
    "#the_model = TheModelClass(*args, **kwargs)\n",
    "#the_model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "#下面是冻结卷积层的方法\n",
    "# fai_model = torchvision.models.resnet18(pretrained=True)\n",
    "# for param in fai_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "#model.fc = nn.Linear(512, 100)\n",
    "# Optimize only the classifier\n",
    "#optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
    "for KEY, MODLE in MODELS.items():\n",
    "    print('######################在{0}下训练8个分类器####################'.format(KEY))\n",
    "    print()\n",
    "    for KEY2,OPTIMIZER in OPTIMIZERS.items():\n",
    "        print('######################在{0}:{1}下训练8个分类器####################'.format(KEY,KEY2))\n",
    "        print()\n",
    "        for cur_class in classes:\n",
    "\n",
    "            print('#######{0}:{1}:{2}####################'.format(KEY,KEY2, cur_class))\n",
    "            #预结构\n",
    "            base_model = MODLE(pretrained=True)\n",
    "\n",
    "            fai_model = FAINET(base_model,fai_classes_num = label_count[cur_class], hidden_feature_size = 512)\n",
    "            #打印含参数各层的名字\n",
    "            #params = fai_model.state_dict()\n",
    "            #for k,v in params.items():\n",
    "            #    print(k)#打印网络中的变量名\n",
    "            #print(fai_model)#可查最后一层Module类对象的名和输入参数，输出参数名，如(fc): Linear(in_features=512, out_features=5, bias=True)\n",
    "\n",
    "\n",
    "            if use_gpu:\n",
    "                #If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. \n",
    "                fai_model = fai_model.cuda()\n",
    "                #多GPU训练用:\n",
    "                #fai_model = torch.nn.DataParallel(module=fai_model.cuda(), device_ids=[0, 3],output_device=0).cuda()#前向在 device_ids，梯度汇总和更新在output_device上\n",
    "            #设置采用多分类的交叉熵loss\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            # 设置优化器，fai_model.parameters()表示优化全部参数@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@这里可设置两部优化法\n",
    "            #torch.optim.Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "            #torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0)\n",
    "            #torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "            #torch.optim.SparseAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "            #class torch.optim.Adamax(params, lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "            #class torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "            #torch.optim.Rprop(params, lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))\n",
    "            #torch.optim.SGD(params, lr=<object object>, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "            optimizer = OPTIMIZER(fai_model.parameters(), lr=learning_rate)\n",
    "            #optimizer = optim.Adam(ai_model.parameters(), lr = learning_rate)#olearning_rate=0.0001,optimizer = optim.Adam([var1, var2], lr = 0.0001)\n",
    "\n",
    "\n",
    "            # Decay LR by a factor of 0.1 every 7 epochs\n",
    "            #与Optimizer类似的是，其主要功能体现在step()方法中，用于更新optimizer对象每个param_group字典的lr键的值。\n",
    "            #scheduler = torch.optim.ReduceLROnPlateau(optimizer, 'min')   scheduler.step(val_loss)\n",
    "            #fai_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=0.1) \n",
    "            fai_lr_scheduler = ReduceLROnPlateau(optimizer, 'max',patience=10,factor = 0.1,verbose = False)\n",
    "\n",
    "            #训练和评估\n",
    "            model = fai_train_model(fai_model, criterion, optimizer, fai_lr_scheduler, batch_size=batch_size,split_ratio=split_ratio,num_epochs=epochs_num,attr=cur_class,model_key=KEY,version=version)\n",
    "            #在测试集上运用训练好的模型，输出csv文件\n",
    "            print('#######{0}:{1}训练完毕，开始在测试集上测试'.format(KEY,cur_class ))\n",
    "            #在cpu上测试\n",
    "            model = model.cpu()\n",
    "            fai_predict(predictor = model,attr=cur_class,model_key=KEY,version=version)\n",
    "            #fai_predict_test_data_visualize(predictor= model, attr=cur_class, n_pictures=8,use_gpu= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T16:24:14.714041Z",
     "start_time": "2018-04-06T13:43:28.318Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################模型实例部署并进行可视化测试#############################################\n",
    "#自定义载入相应模型来自finetune或者是model来自你定义的模型class封装，并进行可视化测试\n",
    "\n",
    "#下面是finetune示例\n",
    "#KEY = finetune改进的模型类型，在此为对应的字符串\n",
    "#预结构\n",
    "#fai_model = models.MODELS[KEY](pretrained=True)\n",
    "#改进的自定义添加\n",
    "#num_ftrs = fai_model.fc.in_features\n",
    "#fai_model.fc = nn.Linear(num_ftrs, label_count[cur_class])\n",
    "\n",
    "#prefix_cls = classes[0].split('_')[0]\n",
    "#PATH = '../models/{0}/pytorch_{0}_{1}_{2}'.format(prefix_cls, model_key=KEY, version=version)\n",
    "#torch.save(model.state_dict(), PATH)\n",
    "#装入训练好的模型的权重\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "#fai_predict_test_data_visualize(predictor = fai_model, classes[0], n_pictures = batch_size,use_gpu= False):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
