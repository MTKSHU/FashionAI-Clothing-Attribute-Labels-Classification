{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T12:48:29.074309Z",
     "start_time": "2018-05-07T12:48:16.516617Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable ## torch中自动计算梯度模块\n",
    "import torch.nn as nn # 神经网络模块\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F  #神经网络模块中的常用功能 \n",
    "import torch.multiprocessing as mp\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets, models\n",
    "from torchvision.models import *\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "#from skimage import io, transform\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()   # interactive mode\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#显示中文字体设置\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Droid Sans Fallback\"]\n",
    "plt.rcParams['axes.unicode_minus'] = False #为了正常显示是\"-\"减号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T12:48:29.325348Z",
     "start_time": "2018-05-07T12:48:29.076683Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = ['collar_design_labels', 'neck_design_labels'] \n",
    "label_count = {'coat_length_labels':8,\n",
    "               'collar_design_labels':5, \n",
    "               'lapel_design_labels':5,\n",
    "               'neck_design_labels':5,\n",
    "               'neckline_design_labels':10,\n",
    "               'pant_length_labels':6, \n",
    "               'skirt_length_labels':6, \n",
    "               'sleeve_length_labels':9}\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "#若gpu可用则返回True\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "#保存文件后缀,即月份和日为版本尾号\n",
    "#version = \"\"\n",
    "version = '0404'\n",
    "image_width = 224\n",
    "epochs_num = 25\n",
    "learning_rate = 0.001\n",
    "split_ratio=0.2\n",
    "batch_size = 16\n",
    "\n",
    "import Augmentor\n",
    "import torchvision\n",
    "p = Augmentor.Pipeline()\n",
    "p.rotate(probability=0.7, max_left_rotation=5, max_right_rotation=5)\n",
    "p.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T12:48:32.874159Z",
     "start_time": "2018-05-07T12:48:29.328450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Images/collar_design_labels/bd0981f231180d2b001d4a37e9834630.jpg', array([0, 1, 0, 0, 0], dtype=uint8))\n",
      "('Images/collar_design_labels/eae3054c14ff6463205ecaadee005251.jpg', array([0, 0, 0, 0, 1], dtype=uint8))\n",
      "('Images/collar_design_labels/677e1183282769a3fe8ac5f1f0154bbd.jpg', array([1, 0, 0, 0, 0], dtype=uint8))\n",
      "1081\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E751896A0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189668>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189828>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E751897B8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189630>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189710>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189B00>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189B38>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189748>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E7518AB38>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189C50>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x298 at 0x7F9E7518A9B0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189C18>]\n",
      "[\n",
      "( 0 , 0 ,.,.) = \n",
      " -1.7240 -1.6727 -1.5870  ...  -1.2788 -1.3815 -1.4329\n",
      " -1.7240 -1.6555 -1.6042  ...  -1.2959 -1.3815 -1.4329\n",
      " -1.7240 -1.6555 -1.6042  ...  -1.2959 -1.3815 -1.4329\n",
      "           ...             ⋱             ...          \n",
      " -0.3541 -0.3883 -0.5253  ...  -0.9363 -0.9534 -0.8678\n",
      " -0.3369 -0.3883 -0.5082  ...  -0.6965 -0.7308 -0.7479\n",
      " -0.3369 -0.3883 -0.4911  ...  -0.5082 -0.5596 -0.6281\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      " -1.6506 -1.6155 -1.5280  ...  -1.3354 -1.4405 -1.4930\n",
      " -1.6506 -1.6331 -1.5805  ...  -1.3354 -1.4405 -1.4930\n",
      " -1.6506 -1.6155 -1.5630  ...  -1.3529 -1.4405 -1.4930\n",
      "           ...             ⋱             ...          \n",
      " -0.7402 -0.7052 -0.7577  ...  -0.4776 -0.4776 -0.3550\n",
      " -0.7227 -0.6877 -0.7402  ...  -0.2150 -0.2500 -0.2325\n",
      " -0.7402 -0.7052 -0.7402  ...  -0.0049 -0.0574 -0.0749\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -1.4907 -1.4733 -1.4036  ...  -1.1770 -1.2990 -1.3861\n",
      " -1.4907 -1.4907 -1.4559  ...  -1.1944 -1.2990 -1.3861\n",
      " -1.5256 -1.5081 -1.4733  ...  -1.1944 -1.2990 -1.3861\n",
      "           ...             ⋱             ...          \n",
      " -0.6367 -0.5321 -0.5495  ...  -1.2990 -1.2816 -1.1944\n",
      " -0.6193 -0.5147 -0.5321  ...  -1.0027 -0.9330 -0.9504\n",
      " -0.6367 -0.5321 -0.5321  ...  -0.7936 -0.7238 -0.7587\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  1.3927  1.5639  1.6495  ...   1.8893  1.9064  1.5810\n",
      "  1.3927  1.5639  1.6495  ...   1.9235  1.9064  1.5810\n",
      "  1.4098  1.5810  1.6667  ...   1.9407  1.9235  1.5810\n",
      "           ...             ⋱             ...          \n",
      "  1.0502  0.9817  0.8276  ...   1.1872  1.2043  1.1872\n",
      "  1.0502  0.9646  0.8104  ...   1.1872  1.2043  1.1872\n",
      "  1.0502  0.9646  0.8104  ...   1.1872  1.2043  1.2043\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  1.5532  1.7283  1.8158  ...   2.0784  2.0434  1.7283\n",
      "  1.5532  1.7283  1.8158  ...   2.0959  2.0609  1.7283\n",
      "  1.5707  1.7458  1.8333  ...   2.1134  2.0784  1.7283\n",
      "           ...             ⋱             ...          \n",
      "  1.1856  1.1155  0.9405  ...   1.3431  1.3431  1.3256\n",
      "  1.2031  1.1155  0.9405  ...   1.3256  1.3431  1.3256\n",
      "  1.2031  1.1155  0.9405  ...   1.3256  1.3431  1.3256\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  1.5942  1.7860  1.8905  ...   2.1868  2.1694  1.8557\n",
      "  1.5942  1.8034  1.8905  ...   2.2043  2.1868  1.8557\n",
      "  1.6117  1.8208  1.9080  ...   2.2217  2.2043  1.8557\n",
      "           ...             ⋱             ...          \n",
      "  1.1934  1.1237  0.9494  ...   1.4374  1.4548  1.4722\n",
      "  1.2108  1.1237  0.9494  ...   1.4200  1.4548  1.4722\n",
      "  1.2108  1.1237  0.9494  ...   1.4200  1.4548  1.4722\n",
      "[torch.FloatTensor of size 2x3x224x224]\n",
      ", \n",
      " 1  0  0  0  0\n",
      " 1  0  0  0  0\n",
      "[torch.ByteTensor of size 2x5]\n",
      "]\n",
      "6714\n",
      "1678\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E75189BE0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8F748>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8F8D0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=311x224 at 0x7F9E74D8F860>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D90860>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8F710>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8FEB8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8FE80>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8FE80>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8FE48>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D907B8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D90F28>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8F6D8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8FE80>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE80B8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE81D0>]\n",
      "[\n",
      "( 0 , 0 ,.,.) = \n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      "           ...             ⋱             ...          \n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      "           ...             ⋱             ...          \n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      "           ...             ⋱             ...          \n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      "           ...             ⋱             ...          \n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      " -2.1179 -2.1179 -2.1179  ...  -2.1179 -2.1179 -2.1179\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      "           ...             ⋱             ...          \n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      " -2.0357 -2.0357 -2.0357  ...  -2.0357 -2.0357 -2.0357\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      "           ...             ⋱             ...          \n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      " -1.8044 -1.8044 -1.8044  ...  -1.8044 -1.8044 -1.8044\n",
      "[torch.FloatTensor of size 2x3x224x224]\n",
      ", \n",
      " 1  0  0  0  0\n",
      " 0  0  1  0  0\n",
      "[torch.ByteTensor of size 2x5]\n",
      "]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFDE1D0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE50B8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFDE2E8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE51D0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8080>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8080>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8198>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8198>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFDE0B8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE5240>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8358>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8048>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8080>]\n",
      "[\n",
      "( 0 , 0 ,.,.) = \n",
      " -0.8164 -0.7822 -0.7479  ...  -0.5767 -0.5767 -0.5596\n",
      " -0.7822 -0.5596  0.8789  ...  -0.5596 -0.5767 -0.5596\n",
      " -0.7650 -0.2684  1.7009  ...  -0.5596 -0.5767 -0.5596\n",
      "           ...             ⋱             ...          \n",
      " -0.2342 -0.2171 -0.2342  ...  -0.7308 -0.7479 -0.7479\n",
      " -0.2513 -0.2342 -0.2513  ...  -0.7308 -0.7479 -0.7479\n",
      " -0.2342 -0.2342 -0.2513  ...  -0.7479 -0.7137 -0.7308\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      " -0.5651 -0.5826 -0.5826  ...  -0.3901 -0.3901 -0.3725\n",
      " -0.5826 -0.4076  1.0280  ...  -0.3725 -0.3901 -0.3725\n",
      " -0.5826 -0.1099  1.8683  ...  -0.3725 -0.3901 -0.3725\n",
      "           ...             ⋱             ...          \n",
      "  0.0651  0.0826  0.0651  ...  -0.5301 -0.5126 -0.5126\n",
      "  0.0476  0.0651  0.0476  ...  -0.5301 -0.5126 -0.5126\n",
      "  0.0651  0.0651  0.0476  ...  -0.5301 -0.4776 -0.4951\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -0.2010 -0.2358 -0.2707  ...   0.0082 -0.0092  0.0082\n",
      " -0.2358 -0.0964  1.3328  ...   0.0431  0.0256  0.0256\n",
      " -0.2881  0.1651  2.1171  ...   0.0431  0.0256  0.0431\n",
      "           ...             ⋱             ...          \n",
      "  0.4439  0.4614  0.4439  ...  -0.1487 -0.1487 -0.1487\n",
      "  0.4265  0.4439  0.4265  ...  -0.1487 -0.1487 -0.1312\n",
      "  0.4614  0.4614  0.4439  ...  -0.1487 -0.1138 -0.0964\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  1.0331  1.0331  1.0331  ...   1.0159  1.0159  0.9988\n",
      "  1.9578  1.9578  1.9578  ...   1.9407  1.9407  1.9407\n",
      "  1.8379  1.8379  1.8379  ...   1.8379  1.8379  1.8379\n",
      "           ...             ⋱             ...          \n",
      "  1.8722  1.8722  1.8722  ...   1.8722  1.8722  1.8722\n",
      "  1.8722  1.8722  1.8722  ...   1.8722  1.8722  1.8722\n",
      "  1.8722  1.8722  1.8722  ...   1.8722  1.8722  1.8722\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  1.7808  1.7808  1.7808  ...   1.7983  1.7983  1.7983\n",
      "  2.0259  2.0259  2.0259  ...   2.0259  2.0434  2.0434\n",
      "  2.0609  2.0609  2.0609  ...   2.0434  2.0434  2.0434\n",
      "           ...             ⋱             ...          \n",
      "  2.0434  2.0434  2.0434  ...   2.0434  2.0434  2.0434\n",
      "  2.0434  2.0434  2.0434  ...   2.0434  2.0434  2.0434\n",
      "  2.0434  2.0434  2.0434  ...   2.0434  2.0434  2.0434\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  2.2217  2.2217  2.2217  ...   2.2217  2.2217  2.2043\n",
      "  2.2043  2.2043  2.2043  ...   2.2043  2.2043  2.2043\n",
      "  2.2914  2.2914  2.2914  ...   2.3088  2.3088  2.3088\n",
      "           ...             ⋱             ...          \n",
      "  2.2566  2.2566  2.2566  ...   2.2566  2.2566  2.2566\n",
      "  2.2566  2.2566  2.2566  ...   2.2566  2.2566  2.2566\n",
      "  2.2566  2.2566  2.2566  ...   2.2566  2.2566  2.2566\n",
      "[torch.FloatTensor of size 2x3x224x224]\n",
      ", \n",
      " 0  1  0  0  0\n",
      " 0  0  1  0  0\n",
      "[torch.ByteTensor of size 2x5]\n",
      "]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE84A8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8E828>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8E780>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8E748>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8E8D0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8E898>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8EEB8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8EE80>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8E6D8>]\n",
      "torch.Size([2, 3, 224, 224]) torch.Size([2, 5])\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8EE80>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8080>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE81D0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8EEB8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8EE80>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE7128>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE50B8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8E710>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE51D0>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8128>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8EF98>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9E74D8E898>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE5240>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=278x224 at 0x7F9EDDFE20B8>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x224 at 0x7F9EDDFE8438>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=278x224 at 0x7F9EDDFE2208>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x279 at 0x7F9EDDFE2048>]\n",
      "立波 [<PIL.Image.Image image mode=RGB size=224x279 at 0x7F9EDDFE22E8>]\n"
     ]
    }
   ],
   "source": [
    "#定义数据预处理\n",
    "fai_data_transforms = {\n",
    "                    'train': transforms.Compose([\n",
    "                        transforms.Resize(224, interpolation=2),\n",
    "                        p.torch_transform(),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "                        transforms.RandomRotation(20, resample=False, expand=False, center=None),\n",
    "                        transforms.RandomResizedCrop(image_width, scale=(0.95, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2),\n",
    "                        \n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "                    'val': transforms.Compose([\n",
    "                        #transforms.Resize(256),\n",
    "                        #transforms.CenterCrop(256,224),\n",
    "                        transforms.Resize(224, interpolation=2),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "fai_test_data_transforms=transforms.Compose([\n",
    "                        transforms.Resize(224),\n",
    "                        p.torch_transform(),\n",
    "                        #transforms.CenterCrop(256,224),\n",
    "                        transforms.Resize(224, interpolation=2),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "#定义数据集\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "class FaiTrainDataset(Dataset):\n",
    "    \"\"\"FaiTrainDataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path_and_file, train_images_root_dir,split_ratio=0.2,transform=None,target_transform=None,loader=default_loader):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_path_and_file)\n",
    "        #self.df_load = df.sample(frac=1).reset_index(drop=True)\n",
    "        self.df_load = self.df.copy()\n",
    "        #df.iloc[np.random.permutation(len(df))]\n",
    "        #self.x, self.y = self.df_load.ix[:,0],self.df_load.ix[:,2:]\n",
    "        #self.x_train,self.x_test,self.y_train,self.y_test = train_test_split(self.x,self.y,test_size=split_ratio,random_state=42)\n",
    "        self.split_ratio = split_ratio\n",
    "        self.cut_idx = int(len(self.df_load)-round(len(self.df_load)*self.split_ratio))#int(round(0.1 * self.df_load.shape[0]))\n",
    "        #self.cut_idx = int(round(len(self.df_load)*self.split_ratio))\n",
    "        #self.b = int(len(self.df_load)*0.2)\n",
    "   \n",
    "        self.df_train= self.df_load.iloc[:self.cut_idx]\n",
    "    \n",
    "        self.df_train_load = self.df_train.copy()\n",
    "        self.df_train_load.columns = ['image_id', 'class', 'label']\n",
    "        self.df_train_load.reset_index(drop=True)\n",
    "        \n",
    "        self.train_images = self.df_train_load['image_id'].tolist()\n",
    "        self.train_labels = self.df_train_load['label'].tolist()\n",
    "        n=len(self.df_train_load)\n",
    "        self.y = np.zeros((n, label_count[self.df_train_load['class'][0]]), dtype=np.uint8)\n",
    "        for i in range(n):\n",
    "            tmp_label=self.train_labels[i]\n",
    "            self.y[i][tmp_label.find('y')] = 1\n",
    "        \n",
    "        self.train_data = list(zip(self.train_images,self.y))\n",
    "        print(self.train_data[0])\n",
    "        \n",
    "        self.train_images_root_dir = train_images_root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "       \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.df_train_load)\n",
    "\n",
    "    def __getitem__(self, index): #最终返回的是Tensor\n",
    "        \n",
    "        image_path, label = self.train_data[index]\n",
    "        img_name = os.path.join(self.train_images_root_dir,image_path)\n",
    "        #image = io.imread(img_name) #用的skimage.io,读入为uint8，RGB，HWc图像\n",
    "        img = self.loader(img_name)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) #处理后为RGB CHW 0-1.0数据\n",
    "        return img,label\n",
    "class FaiValDataset(Dataset):\n",
    "    \"\"\"FaiTrainDataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path_and_file, train_images_root_dir,split_ratio=0.2,transform=None,target_transform=None,loader=default_loader):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_path_and_file)\n",
    "        #self.df_load = df.sample(frac=1).reset_index(drop=True)\n",
    "        self.df_load = self.df.copy()\n",
    "        #df.iloc[np.random.permutation(len(df))]\n",
    "        #self.x, self.y = self.df_load.ix[:,0],self.df_load.ix[:,2:]\n",
    "        #self.x_train,self.x_test,self.y_train,self.y_test = train_test_split(self.x,self.y,test_size=split_ratio,random_state=42)\n",
    "        self.split_ratio = split_ratio\n",
    "        self.cut_idx = int(len(self.df_load)-round(len(self.df_load)*self.split_ratio))#int(round(0.1 * self.df_load.shape[0]))\n",
    "        #self.cut_idx = int(round(len(self.df_load)*self.split_ratio))\n",
    "        #self.b = int(len(self.df_load)*0.2)\n",
    "   \n",
    "        self.df_val= self.df_load.iloc[self.cut_idx:]\n",
    "    \n",
    "        self.df_val_load = self.df_val.copy()\n",
    "        self.df_val_load.columns = ['image_id', 'class', 'label']\n",
    "        self.df_val_load.reset_index(inplace= True,drop=True)\n",
    "        \n",
    "        self.val_images = self.df_val_load['image_id'].tolist()\n",
    "        self.val_labels = self.df_val_load['label'].tolist()\n",
    "        n=len(self.df_val_load)\n",
    "        #print(self.df_val_load['class'])\n",
    "        self.yy = np.zeros((n, label_count[self.df_val_load['class'][0]]), dtype=np.uint8)\n",
    "       \n",
    "        for i in range(n):\n",
    "            tmp_label=self.val_labels[i]\n",
    "            self.yy[i][tmp_label.find('y')] = 1\n",
    "        \n",
    "        self.val_data = list(zip(self.val_images,self.yy))\n",
    "        print(self.val_data[0])\n",
    "        \n",
    "        self.train_images_root_dir = train_images_root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "       \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.df_val_load)\n",
    "\n",
    "    def __getitem__(self, index): #最终返回的是Tensor\n",
    "        \n",
    "        image_path, label = self.val_data[index]\n",
    "        img_name = os.path.join(self.train_images_root_dir,image_path)\n",
    "        #image = io.imread(img_name) #用的skimage.io,读入为uint8，RGB，HWc图像\n",
    "        img = self.loader(img_name)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) #处理后为RGB CHW 0-1.0数据\n",
    "        return img,label\n",
    "\n",
    "#定义测试数据集\n",
    "class FaiTestDataset(Dataset):\n",
    "    \"\"\"FaiTestDataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path_and_file, test_images_root_dir,split_ratio=0.0,transform=None,target_transform=None,loader=default_loader):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_path_and_file)\n",
    "        #self.df_load = df.sample(frac=1).reset_index(drop=True)\n",
    "        self.df_load = self.df.copy()\n",
    "        #df.iloc[np.random.permutation(len(df))]\n",
    "        #self.x, self.y = self.df_load.ix[:,0],self.df_load.ix[:,2:]\n",
    "        #self.x_train,self.x_test,self.y_train,self.y_test = train_test_split(self.x,self.y,test_size=split_ratio,random_state=42)\n",
    "        self.split_ratio = split_ratio\n",
    "        self.cut_idx = int(len(self.df_load)-round(len(self.df_load)*self.split_ratio))#int(round(0.1 * self.df_load.shape[0]))\n",
    "        #self.cut_idx = int(round(len(self.df_load)*self.split_ratio))\n",
    "        #self.b = int(len(self.df_load)*0.2)\n",
    "   \n",
    "        self.df_test= self.df_load.iloc[:self.cut_idx]\n",
    "    \n",
    "        self.df_test_load = self.df_test.copy()\n",
    "        self.df_test_load.columns = ['image_id', 'class', 'label']\n",
    "        self.df_test_load.reset_index(inplace= True,drop=True)\n",
    "        \n",
    "        self.test_images = self.df_test_load['image_id'].tolist()\n",
    "        self.test_labels = self.df_test_load['label'].tolist()\n",
    "        n=len(self.df_test_load)\n",
    "        #print(self.df_test_load['class'])\n",
    "        self.yyy = np.zeros((n, label_count[self.df_test_load['class'][0]]), dtype=np.uint8)\n",
    "       \n",
    "        for i in range(n):\n",
    "            tmp_label=self.test_labels[i]\n",
    "            self.yyy[i][tmp_label.find('?')] = 1\n",
    "        \n",
    "        self.test_data = list(zip(self.test_images,self.yyy))\n",
    "        print(self.test_data[0])\n",
    "        \n",
    "        self.test_images_root_dir = test_images_root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "       \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.df_test_load)\n",
    "\n",
    "    def __getitem__(self, index): #最终返回的是Tensor\n",
    "        \n",
    "        image_path, label = self.test_data[index]\n",
    "        img_name = os.path.join(self.test_images_root_dir,image_path)\n",
    "        #image = io.imread(img_name) #用的skimage.io,读入为uint8，RGB，HWc图像\n",
    "        img = self.loader(img_name)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) #处理后为RGB CHW 0-1.0数据\n",
    "        return img,label\n",
    "\n",
    "    \n",
    "    \n",
    "fai_train_dataset = FaiTrainDataset(csv_path_and_file='../train/Annotations/{0}.csv'.format(classes[0]),\n",
    "                                   train_images_root_dir='../train/',\n",
    "                                   split_ratio=split_ratio,\n",
    "                                   transform = fai_data_transforms['train'])\n",
    "fai_val_dataset = FaiValDataset(csv_path_and_file='../train/Annotations/{0}.csv'.format(classes[0]),\n",
    "                                   train_images_root_dir='../train/',\n",
    "                                   split_ratio=split_ratio,\n",
    "                                   transform = fai_data_transforms['val'])\n",
    "\n",
    "fai_test_dataset = FaiTestDataset(csv_path_and_file='../test/Tests/{0}.csv'.format(classes[0]),\n",
    "                                  test_images_root_dir='../test/',\n",
    "                                  transform = fai_test_data_transforms)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(fai_train_dataset, batch_size=2,shuffle=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(fai_val_dataset, batch_size=2,shuffle=True, num_workers=1)\n",
    "test_dataloader = torch.utils.data.DataLoader(fai_test_dataset, batch_size=2,shuffle=True, num_workers=4)\n",
    "#test_dataloader = torch.utils.data.DataLoader(fai_test_dataset, batch_size=4,shuffle=False, num_workers=4)\n",
    "print(len(fai_test_dataset))\n",
    "\n",
    "print(next(iter(test_dataloader)))\n",
    "\n",
    "print(len(fai_train_dataset))\n",
    "print(len(fai_val_dataset))\n",
    "#next(iter(train_dataloader))\n",
    "print(next(iter(train_dataloader)))\n",
    "print(next(iter(val_dataloader)))\n",
    "samples,labels = next(iter(train_dataloader))\n",
    "print(samples.size(),labels.size())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
