{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法:使用Keras提供的其他优化器，如梯度下降，看在其他算法下模型参数对模型训练和过拟合的速度有怎样的影响。\n",
    "损失函数:尝试使用Keras其他可用的损失函数，探究选用其他的损失函数是否可以提升模型的性能。\n",
    "学习率与迭代次数更新策略\n",
    "更大的Batch Size:使用更大的Batch Size意味着模型在训练集和测试集上的数据操作规模更大了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from keras.layers import *\n",
    "#from keras.layers import Input\n",
    "from keras.models import *\n",
    "#from keras.models import Model\n",
    "#from keras.layers import Input, Dense\n",
    "#a = Input(shape=(32,))\n",
    "#b = Dense(32)(a)\n",
    "#model = Model(inputs=a, outputs=b)\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras import initializers\n",
    "from keras.applications import *\n",
    "\n",
    "#from keras.utils import multi_gpu_model \n",
    "#from keras.applications import ResNet50\n",
    "#from keras.applications import VGG16\n",
    "#from keras.applications import VGG19\n",
    "#from keras.applications import Xception # TensorFlow ONLY\n",
    "#from keras.applications import InceptionResNetV2\n",
    "#from keras.applications import InceptionV3\n",
    "\n",
    "#tf.keras.applications.inception_v3.InceptionV3\n",
    "#tf.keras.applications.inception_resnet_v2.InceptionResNetV2\n",
    "####################################################################\n",
    "#设置GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "#设置项\n",
    "#看具体的模型参数设置在:https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "MODELS = {\"InceptionResNetV2\":InceptionResNetV2}\n",
    "#MODELS = {\"NASNetLarge\":NASNetLarge,\"VGG16\":VGG16}\n",
    "#\"InceptionV3\":InceptionV3,\"DenseNet121\":DenseNet121,\n",
    " #       \"DenseNet169\":DenseNet169,\"DenseNet201\":DenseNet201,\"Xception\":Xception, \n",
    " #       \"InceptionResNetV2\":InceptionResNetV2,\n",
    "#\"ResNet50\":ResNet50, \n",
    "#\"VGG16\":VGG16,\"VGG16\":VGG19,\"NASNetMobile\":NASNetMobile\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "classes = ['coat_length_labels','collar_design_labels', 'lapel_design_labels',\n",
    "           'neck_design_labels','neckline_design_labels',\n",
    "           'pant_length_labels', 'skirt_length_labels', \n",
    "           'sleeve_length_labels']    \n",
    "fai_result = []\n",
    "label_count = {'coat_length_labels':8,\n",
    "               'collar_design_labels':5, \n",
    "               'lapel_design_labels':5,\n",
    "               'neck_design_labels':5,\n",
    "               'neckline_design_labels':10,\n",
    "               'pant_length_labels':6, \n",
    "               'skirt_length_labels':6, \n",
    "               'sleeve_length_labels':9}\n",
    "#####################\n",
    "width = 299\n",
    "#####################\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('../train/Annotations/train.csv', header=None)\n",
    "\n",
    "df_train.columns = ['image_id', 'class', 'label']\n",
    "df_load = df_train.copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "#样本总数 \n",
    "n = len(df_load)\n",
    "X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, 54), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    tmp_label = df_load['label'][i]\n",
    "    n_class = len(df_load['label'][0])\n",
    "    if len(tmp_label) == label_count[df_load['class'][i]]:\n",
    "        \n",
    "        X[i] = cv2.resize(cv2.imread('../train/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "        if df_load['class'][i] == 'coat_length_labels':\n",
    "            y[i][tmp_label.find('y')] = 1\n",
    "        elif df_load['class'][i] == 'collar_design_labels':\n",
    "            kk = y[i][tmp_label.find('y')] + 8\n",
    "            y[i][kk] = 1\n",
    "        elif df_load['class'][i] == 'lapel_design_labels':\n",
    "            kk = y[i][tmp_label.find('y')] + 13\n",
    "            y[i][kk] = 1\n",
    "        elif df_load['class'][i] == 'neck_design_labels':\n",
    "            kk = y[i][tmp_label.find('y')] + 18\n",
    "            y[i][kk] = 1\n",
    "        elif df_load['class'][i] == 'neckline_design_labels':\n",
    "            kk = y[i][tmp_label.find('y')] + 23\n",
    "            y[i][kk] = 1\n",
    "        elif df_load['class'][i] == 'pant_length_labels':\n",
    "            kk = y[i][tmp_label.find('y')] + 33\n",
    "            y[i][kk] = 1\n",
    "        elif df_load['class'][i] == 'skirt_length_labels':\n",
    "            kk = y[i][tmp_label.find('y')] + 39\n",
    "            y[i][kk] = 1\n",
    "        else:\n",
    "            kk = y[i][tmp_label.find('y')] + 45\n",
    "            y[i][kk] = 1          \n",
    "print(\"数据装载到内存完毕:{0}\".format(\"label:54-one-hot,下面训练一个分类器\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for KEY, MODLE in MODELS.items():\n",
    "    #\n",
    "    n_class = 54\n",
    "    #为299*299,设置如下\n",
    "    ppreprocess = preprocess_input\n",
    "    if KEY in [\"InceptionV3\",\"Xception\", \"InceptionResNetV2\"]:\n",
    "        width = 299\n",
    "    elif KEY == \"NASNetLarge\":\n",
    "        width = 331\n",
    "    else:\n",
    "        width = 224\n",
    "        ppreprocess = imagenet_utils.preprocess_input \n",
    "    print('######################在{0}下训练8个分类器####################'.format(KEY))\n",
    "    cnn_model = MODLE(include_top=False, input_shape=(width, width, 3), weights='imagenet',pooling='avg')\n",
    "    inputs = Input((width, width, 3))\n",
    "    x = inputs\n",
    "    x = Lambda(ppreprocess, name='preprocessing')(x)\n",
    "    x = cnn_model(x)\n",
    "    #下面是新加的层\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Flatten(name='flatten')(x)\n",
    "    #x = Dense(2048, activation='relu', name='fc1')(x)\n",
    "    # n_class为对应属性的分类个数\n",
    "    #x = Dense(256, activation='relu', kernel_initializer=initializers.he_uniform(seed=None),name='fc1')(x)\n",
    "    x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.12, random_state=50)\n",
    "        \n",
    "    #sgd = SGD(lr=learning_rate, decay=learning_rate/nb_epoch, momentum=0.9, nesterov=True)\n",
    "    #adam = optimizers.Adam(lr=1e-4)\n",
    "    #optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "    adam = Adam(lr=0.001)\n",
    "        \n",
    "    #多GPU训练,因为keras设计的自动保存最好模型,但是多GPU训练,其save()就没法用了\n",
    "    #model = multi_gpu_model(model, 2)  \n",
    "\n",
    "    model.compile(optimizer=adam,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Callback that implements learning rate schedule\n",
    "#schedule = Step([20], [1e-4, 1e-6])\n",
    "#history = model.fit(X_train, Y_train,\n",
    "#                    batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test,Y_test),\n",
    "#                    callbacks=[\n",
    "#                           schedule,\n",
    "#                           keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "\n",
    "# 该回调函数将在每个epoch后保存模型到filepath\n",
    "#keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "# 当监测值不再改善时，该回调函数将中止训练.\n",
    "#当early stop被激活（如发现loss相比上一个epoch训练没有下降），则经过patience个epoch后停止训练\n",
    "#keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "    #设置训练完之后,最好的模型保存路径\n",
    "    #checkpointer = ModelCheckpoint(filepath='../models/{0}.best.h5'.format(KEY), verbose=1, \n",
    "                                  #  save_best_only=True)\n",
    "    #训练开始,并保存训练过程的loss和acc变化\n",
    "    h = model.fit(X_train, y_train, batch_size=6, epochs=8, \n",
    "                     # callbacks=[EarlyStopping(patience=10), checkpointer], \n",
    "                      shuffle=True, \n",
    "                      validation_data=(X_valid,y_valid))\n",
    "    #score = model.evaluate(X_valid,y_valid,batch_size=64,verbose=0)\n",
    "    #print ('{0}验证平均accuracy:{1}'.format(KEY,score[1]))\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history['loss'])\n",
    "    plt.plot(h.history['val_loss'])\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('{0}_loss'.format(KEY))\n",
    "        \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history['acc'])\n",
    "    plt.plot(h.history['val_acc'])\n",
    "    plt.legend(['acc', 'val_acc'])\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('{0}_accuracy'.format(KEY))\n",
    "    #保存训练损失和准确率变化的图像\n",
    "    plt.savefig('../models/{0}v.png'.format(KEY),bbox_inches='tight')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#测试集上预测并输出结果\n",
    "df_test = pd.read_csv('../test/Tests/question.csv', header=None)\n",
    "df_test.columns = ['image_id', 'class', 'x']\n",
    "del df_test['x']  \n",
    "df_load = df_test.copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']  \n",
    "n = len(df_load)\n",
    "X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    X_test[i] = cv2.resize(cv2.imread('../test/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "\n",
    "test_np = model.predict(X_test, batch_size=256)\n",
    "print(test_np)\n",
    "result = []\n",
    "for i, row in df_load.iterrows():\n",
    "    tmp_list = test_np[i]\n",
    "    tmp_label = df_load['label'][i]\n",
    "    tmp_result = \"\"\n",
    "    if df_load['class'][i] == 'coat_length_labels':\n",
    "        dd = 0\n",
    "        aa = 8\n",
    "    elif df_load['class'][i] == 'collar_design_labels':\n",
    "        dd = 8\n",
    "        aa = 13\n",
    "    elif df_load['class'][i] == 'lapel_design_labels':\n",
    "        dd = 13\n",
    "        aa = 18\n",
    "    elif df_load['class'][i] == 'neck_design_labels':\n",
    "        dd = 18\n",
    "        aa = 23\n",
    "    elif df_load['class'][i] == 'neckline_design_labels':\n",
    "        dd = 23\n",
    "    elif df_load['class'][i] == 'pant_length_labels':\n",
    "        dd = 33\n",
    "        aa = 39\n",
    "    elif df_load['class'][i] == 'skirt_length_labels':\n",
    "        dd = 39\n",
    "        aa = 45\n",
    "    else:\n",
    "        dd = 45 \n",
    "        aa = 54\n",
    "    tmp_listdd = tmp_list[dd:aa]\n",
    "    for tmp_ret in tmp_listdd:\n",
    "            \n",
    "        tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "\n",
    "    result.append(tmp_result[:-1])\n",
    "\n",
    "df_load['result'] = result     \n",
    "df_load.to_csv('../result/{0}/{0}.csv'.format(KEY), header=None, index=False)\n",
    "print(fai_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fai_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
