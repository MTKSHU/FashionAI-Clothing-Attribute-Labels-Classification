{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()   # interactive mode 画图不阻止程序运行\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "#from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras import initializers\n",
    "\n",
    "\n",
    "\n",
    "#from keras.utils import multi_gpu_model \n",
    "#from keras.applications import ResNet50\n",
    "#from keras.applications import VGG16\n",
    "#from keras.applications import VGG19\n",
    "#from keras.applications import Xception # TensorFlow ONLY\n",
    "#from keras.applications import InceptionResNetV2\n",
    "#from keras.applications import InceptionV3\n",
    "\n",
    "####################################################################\n",
    "#设置可见的GPU数,注意不是并行训练的设置\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "#看具体的模型参数设置在:https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "MODEL = {\"InceptionResNetV2\":InceptionResNetV2}\n",
    "#MODELS = {\"DenseNet121\":DenseNet121,\"DenseNet201\":DenseNet201,\"InceptionResNetV2\":InceptionResNetV2}\n",
    "#\"InceptionV3\":InceptionV3,\"DenseNet121\":DenseNet121,\n",
    "#       \"DenseNet169\":DenseNet169,\"DenseNet201\":DenseNet201,\"Xception\":Xception, \n",
    "#       \"InceptionResNetV2\":InceptionResNetV2,\n",
    "\n",
    "#classes = ['pant_length_labels','coat_length_labels'] \n",
    "classes = ['collar_design_labels', 'neckline_design_labels', 'neck_design_labels']   \n",
    "#记录各分类的最高验证率 \n",
    "fai_result = []\n",
    "#不同参数设置不同版本\n",
    "version = \"bestV1\"\n",
    "#version = [\"bestV1\",\"bestV2\",\"bestV3\",\"bestV4\",\"bestV5\"]\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppreprocess = preprocess_input\n",
    "if KEY in [\"InceptionV3\",\"Xception\", \"InceptionResNetV2\"]:\n",
    "    width = 299\n",
    "elif KEY == \"NASNetLarge\":\n",
    "    width = 331\n",
    "else:\n",
    "    width = 224\n",
    "    ppreprocess = imagenet_utils.preprocess_input \n",
    "print('######################在{0}下训练8个分类器####################'.format(KEY))\n",
    "#数据重读在for循环中有利于减小每次装入内存的数据量,切数据每次预处理会增加数据的多样性\n",
    "for cur_class in classes:\n",
    "    print('#######{0}:{1}####################'.format(KEY,cur_class ))\n",
    "    df_train = pd.read_csv('../train/Annotations/{0}.csv'.format(cur_class), header=None)\n",
    "    #对载入内存副本的表,命名各series列的名称\n",
    "    df_train.columns = ['image_id', 'class', 'label']\n",
    "    df_load = df_train.copy()\n",
    "\n",
    "    #当从train.csv抽取对应class的行时,需重置索引\n",
    "    #默认为inplace=False,返回一个拷贝,原df_load不变,这里是直接改变原表的索引\n",
    "    #默认下,重置索引会增加index索引列(其保存的是原有的索引列),所以可设置drop=Ture,或用如下方法删去原有索引\n",
    "    df_load.reset_index(inplace=True)\n",
    "    del df_load['index']\n",
    "\n",
    "    n = len(df_load)\n",
    "    n_class = len(df_load['label'][0])\n",
    "    prefix_cls = cur_class.split('_')[0]\n",
    "    print(\"选择的属性为:{0}, 种类的为:{1},样本数: {2}\".format(cur_class, n_class, n))\n",
    "\n",
    "    #图像尺度化,并读入内存,标签转化后也读入内存\n",
    "    X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "    y = np.zeros((n, n_class), dtype=np.uint8)\n",
    "    for i in range(n):\n",
    "        tmp_label = df_load['label'][i]\n",
    "        if len(tmp_label) > n_class:\n",
    "            print(df_load['image_id'][i])\n",
    "        X[i] = cv2.resize(cv2.imread('../train/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "        y[i][tmp_label.find('y')] = 1\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=60)\n",
    "    print(\"数据装载到内存和数据分割完毕:{0},{1}\".format(KEY,cur_class))\n",
    "\n",
    "    #随机抽取内存图片,展示图片样例,2行4列\n",
    "    #plt.figure(figsize=(12, 7))\n",
    "    #for i in range(8):\n",
    "        #random_index = random.randint(0, n-1)\n",
    "        #plt.subplot(2, 4, i+1)\n",
    "        #plt.imshow(X[random_index][:,:,::-1])\n",
    "        #plt.title(y[random_index])\n",
    "    #plt.savefig('../images/{0}/{0}_{1}_{2}.png'.format(prefix_cls, KEY, version),bbox_inches='tight')\n",
    "\n",
    "\n",
    "    #定义模型\n",
    "    #定义要finetune的模型结构\n",
    "    cnn_model = MODLE(include_top=False, input_shape=(width, width, 3), weights='imagenet'，pooling='max')\n",
    "    #输入模型网络的图片shape,如x = Input(shape=(256, 256, 3))\n",
    "    inputs = Input((width, width, 3))#inputs = Input(shape=(784,))\n",
    "    x = inputs\n",
    "    #装入内存图片的预处理操作\n",
    "    x = Lambda(ppreprocess, name='preprocessing')(x)\n",
    "    #构建网络各模块逻辑连接\n",
    "    x = cnn_model(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    ######下面是新加的层########\n",
    "    #因为设置了全局均值采样,所以没有flatten\n",
    "    #x = Flatten(name='flatten')(x)#其他形式:model.add(Flatten()),out = Flatten()(x)\n",
    "    #x = Dense(256, activation='relu',kernel_initializer=initializers.he_uniform(seed=None), name='fc1')(x)\n",
    "    # n_class为对应属性的分类个数\n",
    "    #predictions = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "    #将构建的模型网络实例化\n",
    "    #x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    # n_class为对应属性的分类个\n",
    "     x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu', kernel_initializer=initializers.he_uniform(seed=None),name='fc2')(x)\n",
    "    x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = predictions)\n",
    "\n",
    "    #设置权参优化方法\n",
    "    #optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    optimizer = SGD(lr=0.01, decay=0.01/40, momentum=0.9, nesterov=True)\n",
    "    #optimizer = optimizers.Adam(lr=1e-4)\n",
    "    #optimizer = Adam(lr=0.0001)\n",
    "    #optimizer = 'rmsprop'\n",
    "\n",
    "    #设置多GPU数据并行训练\n",
    "    #多GPU训练,因为keras设计的自动保存最好模型,但是多GPU训练,其save()就没法用了,需定义各保存函数\n",
    "    #model = multi_gpu_model(model, 2)  \n",
    "\n",
    "    #所构建模型的编译,其中loss和metrics都可自定义,metrics=['accuracy',func自定义评价]\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Callback实现学习率调整方案和保存最好模型即EarlyStopping\n",
    "    #schedule = Step([20], [1e-4, 1e-6])\n",
    "    #history = model.fit(X_train, Y_train,\n",
    "    #                    batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test,Y_test),\n",
    "    #                    callbacks=[schedule, keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "    #当监测值不再改善时，该回调函数将中止训练.\n",
    "    #当early stop被激活（如发现loss相比上一个epoch训练没有下降），则经过patience个epoch后停止训练\n",
    "    #keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "    #设置训练完之后,最好的模型保存路径,可设置监控准确率而不是监控loss的变化,如monitor='val_acc'\n",
    "    #checkpointer = ModelCheckpoint(filepath='../models/{0}/{0}_{1}_{2}.best.h5'.format(prefix_cls, KEY, version), verbose=1, save_best_only=True)\n",
    "    #训练开始,并保存训练过程的loss和acc变化,h代表history\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
    "      #                    patience=5, min_lr=0.001)\n",
    "    h = model.fit(X_train, y_train, batch_size=10, epochs=36, \n",
    "                  #callbacks=[EarlyStopping(patience=22), checkpointer], \n",
    "                  #callbacks=[reduce_lr],\n",
    "                  shuffle=True, \n",
    "                  validation_data=(X_valid,y_valid))\n",
    "    #保存模型\n",
    "    print(\"开始保存模型\")\n",
    "    model.save_weights('../models/{0}/{0}_{1}_{2}.best.h5'.format(prefix_cls, KEY, version))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
