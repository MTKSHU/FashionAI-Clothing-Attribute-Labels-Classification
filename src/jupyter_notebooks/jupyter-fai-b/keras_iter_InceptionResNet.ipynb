{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法:使用Keras提供的其他优化器，如梯度下降，看在其他算法下模型参数对模型训练和过拟合的速度有怎样的影响。\n",
    "损失函数:尝试使用Keras其他可用的损失函数，探究选用其他的损失函数是否可以提升模型的性能。\n",
    "学习率与迭代次数更新策略\n",
    "更大的Batch Size:使用更大的Batch Size意味着模型在训练集和测试集上的数据操作规模更大了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T08:09:02.852275Z",
     "start_time": "2018-03-28T08:09:00.460229Z"
    }
   },
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()   # interactive mode 画图不阻止程序运行\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications import *\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "#from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras import initializers\n",
    "\n",
    "\n",
    "\n",
    "#from keras.utils import multi_gpu_model \n",
    "\n",
    "####################################################################\n",
    "#设置可见的GPU数,注意不是并行训练的设置\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "#看具体的模型参数设置在:https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "MODELS = {\"InceptionResNetV2\":InceptionResNetV2}\n",
    "#MODELS = {\"DenseNet121\":DenseNet121,\"DenseNet201\":DenseNet201,\"InceptionResNetV2\":InceptionResNetV2}\n",
    "#\"InceptionV3\":InceptionV3,\"DenseNet121\":DenseNet121,\n",
    "#       \"DenseNet169\":DenseNet169,\"DenseNet201\":DenseNet201,\"Xception\":Xception, \n",
    "#       \"InceptionResNetV2\":InceptionResNetV2,\n",
    "\n",
    "#classes = ['pant_length_labels','coat_length_labels'] \n",
    "classes = ['collar_design_labels', 'neckline_design_labels', 'neck_design_labels']   \n",
    "#记录各分类的最高验证率 \n",
    "fai_result = []\n",
    "#不同参数设置不同版本\n",
    "version = \"bestV1\"\n",
    "#version = [\"bestV1\",\"bestV2\",\"bestV3\",\"bestV4\",\"bestV5\"]\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-28T08:09:00.459Z"
    }
   },
   "outputs": [],
   "source": [
    "for KEY, MODLE in MODELS.items():\n",
    "    #为299*299,设置如下\n",
    "    ppreprocess = preprocess_input\n",
    "    if KEY in [\"InceptionV3\",\"Xception\", \"InceptionResNetV2\"]:\n",
    "        width = 299\n",
    "    elif KEY == \"NASNetLarge\":\n",
    "        width = 331\n",
    "    else:\n",
    "        width = 224\n",
    "        ppreprocess = imagenet_utils.preprocess_input \n",
    "    print('######################在{0}下训练8个分类器####################'.format(KEY))\n",
    "    #数据重读在for循环中有利于减小每次装入内存的数据量,切数据每次预处理会增加数据的多样性\n",
    "    for cur_class in classes:\n",
    "        print('#######{0}:{1}####################'.format(KEY,cur_class ))\n",
    "        df_train = pd.read_csv('../train/Annotations/{0}.csv'.format(cur_class), header=None)\n",
    "        #对载入内存副本的表,命名各series列的名称\n",
    "        df_train.columns = ['image_id', 'class', 'label']\n",
    "        df_load = df_train.copy()\n",
    "        \n",
    "        #当从train.csv抽取对应class的行时,需重置索引\n",
    "        #默认为inplace=False,返回一个拷贝,原df_load不变,这里是直接改变原表的索引\n",
    "        #默认下,重置索引会增加index索引列(其保存的是原有的索引列),所以可设置drop=Ture,或用如下方法删去原有索引\n",
    "        df_load.reset_index(inplace=True)\n",
    "        del df_load['index']\n",
    "        \n",
    "        n = len(df_load)\n",
    "        n_class = len(df_load['label'][0])\n",
    "        prefix_cls = cur_class.split('_')[0]\n",
    "        print(\"选择的属性为:{0}, 种类的为:{1},样本数: {2}\".format(cur_class, n_class, n))\n",
    "        \n",
    "        #图像尺度化,并读入内存,标签转化后也读入内存\n",
    "        X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "        y = np.zeros((n, n_class), dtype=np.uint8)\n",
    "        for i in range(n):\n",
    "            tmp_label = df_load['label'][i]\n",
    "            if len(tmp_label) > n_class:\n",
    "                print(df_load['image_id'][i])\n",
    "            X[i] = cv2.resize(cv2.imread('../train/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "            y[i][tmp_label.find('y')] = 1\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=60)\n",
    "        print(\"数据装载到内存和数据分割完毕:{0},{1}\".format(KEY,cur_class))\n",
    "        \n",
    "        #随机抽取内存图片,展示图片样例,2行4列\n",
    "        #plt.figure(figsize=(12, 7))\n",
    "        #for i in range(8):\n",
    "            #random_index = random.randint(0, n-1)\n",
    "            #plt.subplot(2, 4, i+1)\n",
    "            #plt.imshow(X[random_index][:,:,::-1])\n",
    "            #plt.title(y[random_index])\n",
    "        #plt.savefig('../images/{0}/{0}_{1}_{2}.png'.format(prefix_cls, KEY, version),bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "        #定义模型\n",
    "        #定义要finetune的模型结构\n",
    "        cnn_model = MODLE(include_top=False, input_shape=(width, width, 3), weights='imagenet',pooling = 'avg')\n",
    "        #输入模型网络的图片shape,如x = Input(shape=(256, 256, 3))\n",
    "        inputs = Input((width, width, 3))#inputs = Input(shape=(784,))\n",
    "        x = inputs\n",
    "        #装入内存图片的预处理操作\n",
    "        x = Lambda(ppreprocess, name='preprocessing')(x)\n",
    "        #构建网络各模块逻辑连接\n",
    "        x = cnn_model(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        #x = AverragePooling2D(pool_size=(2, 2))(x)\n",
    "        ######下面是新加的层########\n",
    "        #因为设置了全局均值采样,所以没有flatten\n",
    "        #x = Flatten(name='flatten')(x)#其他形式:model.add(Flatten()),out = Flatten()(x)\n",
    "        x = Dense(1024, activation='relu',kernel_initializer=initializers.he_uniform(seed=None), name='fc1')(x)\n",
    "        # n_class为对应属性的分类个数\n",
    "        predictions = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "        #将构建的模型网络实例化\n",
    "        model = Model(inputs = inputs, outputs = predictions)\n",
    "        \n",
    "        #设置权参优化方法\n",
    "        optimizer = SGD(lr=0.001, decay=0.1, momentum=0.9, nesterov=True)\n",
    "        #optimizer = optimizers.Adam(lr=1e-4)\n",
    "        #optimizer = Adam(lr=0.0001)\n",
    "        #optimizer = 'rmsprop'\n",
    "        \n",
    "        #设置多GPU数据并行训练\n",
    "        #多GPU训练,因为keras设计的自动保存最好模型,但是多GPU训练,其save()就没法用了,需定义各保存函数\n",
    "        #model = multi_gpu_model(model, 2)  \n",
    "        \n",
    "        #所构建模型的编译,其中loss和metrics都可自定义,metrics=['accuracy',func自定义评价]\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Callback实现学习率调整方案和保存最好模型即EarlyStopping\n",
    "        #schedule = Step([20], [1e-4, 1e-6])\n",
    "        #history = model.fit(X_train, Y_train,\n",
    "        #                    batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test,Y_test),\n",
    "        #                    callbacks=[schedule, keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, mode='auto')\n",
    "        #当监测值不再改善时，该回调函数将中止训练.\n",
    "        #当early stop被激活（如发现loss相比上一个epoch训练没有下降），则经过patience个epoch后停止训练\n",
    "        #keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "        #设置训练完之后,最好的模型保存路径,可设置监控准确率而不是监控loss的变化,如monitor='val_acc'\n",
    "        #checkpointer = ModelCheckpoint(filepath='../models/{0}/{0}_{1}_{2}.best.h5'.format(prefix_cls, KEY, version), verbose=1, save_best_only=True)\n",
    "        #训练开始,并保存训练过程的loss和acc变化,h代表history\n",
    "        #reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
    "          #                    patience=5, min_lr=0.001)\n",
    "        h = model.fit(X_train, y_train, batch_size=10, epochs=36, \n",
    "                      #callbacks=[EarlyStopping(patience=22), checkpointer], \n",
    "                      #callbacks=[reduce_lr],\n",
    "                      shuffle=True, \n",
    "                      validation_data=(X_valid,y_valid))\n",
    "        #保存模型\n",
    "        print(\"开始保存模型\")\n",
    "        model.save_weights('../models/{0}/{0}_{1}_{2}.best.h5'.format(prefix_cls, KEY, version))\n",
    "        #是指取最后一个epochs训练得到的模型做一次整个验证集的准确率测试\n",
    "        #score = model.evaluate(X_valid,y_valid,batch_size=32,verbose=0)\n",
    "        #print ('{0}_{1}_{2}验证平均accuracy:{3}'.format(prefix_cls,KEY,version,score[1]))\n",
    "        print(\"保存模型完成\")\n",
    "        #保存loss和acc的变化曲线\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(h.history['loss'])\n",
    "        plt.plot(h.history['val_loss'])\n",
    "        plt.legend(['loss', 'val_loss'])\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('{0}_{1}_loss'.format(prefix_cls, KEY))\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(h.history['acc'])\n",
    "        plt.plot(h.history['val_acc'])\n",
    "        plt.legend(['acc', 'val_acc'])\n",
    "        plt.ylabel('acc')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('{0}_{1}_accuracy'.format(prefix_cls, KEY))\n",
    "        #保存损失和准确率变化的图像\n",
    "        plt.savefig('../models/{0}/{0}_{1}_{2}.png'.format(prefix_cls, KEY,version),bbox_inches='tight')\n",
    "        #显示图像\n",
    "        plt.show()\n",
    "\n",
    "        for valacc in h.history['val_acc']:\n",
    "            if valacc >= 87:\n",
    "                \n",
    "                fai_result.append['{0}_{1}'.format(prefix_cls, KEY)]\n",
    "        print(h.history['val_acc'])\n",
    "        print(fai_result)\n",
    "        \n",
    "        #在测试集上预测并保存结果\n",
    "        df_test = pd.read_csv('../test/Tests/question.csv', header=None)\n",
    "        #定义各列名称\n",
    "        df_test.columns = ['image_id', 'class', 'x']\n",
    "        del df_test['x']\n",
    "        df_load = df_test[(df_test['class'] == cur_class)].copy()\n",
    "        df_load.reset_index(inplace=True)\n",
    "        del df_load['index']\n",
    "        \n",
    "        n = len(df_load)\n",
    "        X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "        #读取测试集图像到内存并resize\n",
    "        for i in range(n):\n",
    "            X_test[i] = cv2.resize(cv2.imread('../test/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "        #以batch_size处理的速度遍历测试集,处理并预测\n",
    "        test_np = model.predict(X_test, batch_size=10)\n",
    "        result = []\n",
    "        for i, row in df_load.iterrows():\n",
    "            tmp_list = test_np[i]\n",
    "            tmp_result = ''\n",
    "            for tmp_ret in tmp_list:\n",
    "                tmp_result += '{:.6f};'.format(tmp_ret)\n",
    "            #不要最后一个分号\n",
    "            result.append(tmp_result[:-1])\n",
    "        #预测结果导入内存表格的result列\n",
    "        df_load['result'] = result     \n",
    "        df_load.to_csv('../result/{1}/{0}_{1}_{2}.csv'.format(prefix_cls, KEY, version), header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
