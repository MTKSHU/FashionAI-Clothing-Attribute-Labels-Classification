{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据,并设置加载哪个属性的数据用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../train/Annotations/train.csv', header=None)\n",
    "df_train.columns = ['image_id', 'class', 'label']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#:设置加载哪个属性的数据用于训练\n",
    "classes = ['collar_design_labels', 'neckline_design_labels', 'skirt_length_labels', \n",
    "           'sleeve_length_labels', 'neck_design_labels', 'coat_length_labels', 'lapel_design_labels', \n",
    "           'pant_length_labels']\n",
    "\n",
    "###################################################\n",
    "#设置加载那个属性的数据用于训练:\n",
    "cur_class = classes[0]\n",
    "\n",
    "#设置输入训练模型的图像尺寸,注意:有些使224*224,有些是要求299*299\n",
    "width = 299\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抽取相应属性数据到内存的表格\n",
    "df_load = df_train[(df_train['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print(\"选择的属性为:{0}, 种类的为:{1},样本数: {2}\".format(cur_class , len(df_load['label'][0]),len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load[(df_load.index == 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载表格图像并resize到内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意这里的图像resize的设置!!!\n",
    "n = len(df_load)\n",
    "n_class = len(df_load['label'][0])\n",
    "X = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, n_class), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    tmp_label = df_load['label'][i]\n",
    "    if len(tmp_label) > n_class:\n",
    "        print(df_load['image_id'][i])\n",
    "    X[i] = cv2.resize(cv2.imread('../train/{0}'.format(df_load['image_id'][i])), (width, width))\n",
    "    y[i][tmp_label.find('y')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "for i in range(8):\n",
    "    random_index = random.randint(0, n-1)\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(X[random_index][:,:,::-1])\n",
    "    plt.title(y[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#注意要from keras.applications import 可以导入所有可用模型,但要注意:\n",
    "#image size为224*224的预处理函数不同于image size为229*229!!! 如下:\n",
    "\n",
    "#预处理函数:\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "#导入的image_utils包包含了一系列函数，使得对图片进行前处理以及对分类结果解码更加容易\n",
    "#VGG16，VGG19以及ResNet接受224×224的输入图像， 而Inception V3和Xception要求为299×299\n",
    "#使用合适的预处理函数来执行mean subtraction/scaling\n",
    "#预处理 图像编码服从规定，譬如,RGB，GBR这一类的，preprocess_input(x)  \n",
    "#preprocessing function is also different (same as Xception)\n",
    "#return imagenet_utils.preprocess_input(x, mode='tf')\n",
    "#而其他VGG16，VGG19以及ResNet接受224×224的输入图像,使用preprocess = imagenet_utils.preprocess_input预处理\n",
    "#InceptionV3和Xception,还有   \n",
    "#########################################################\n",
    "\n",
    "from keras.layers import *\n",
    "#from keras.layers import Input\n",
    "from keras.models import *\n",
    "#from keras.models import Model\n",
    "#from keras.layers import Input, Dense\n",
    "#a = Input(shape=(32,))\n",
    "#b = Dense(32)(a)\n",
    "#model = Model(inputs=a, outputs=b)\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "# \n",
    "from keras.applications import *\n",
    "#from keras.applications import ResNet50\n",
    "#from keras.applications import VGG16\n",
    "#from keras.applications import VGG19\n",
    "#from keras.applications import Xception # TensorFlow ONLY\n",
    "#from keras.applications import InceptionResNetV2\n",
    "#from keras.applications import InceptionV3\n",
    "\n",
    "#tf.keras.applications.inception_v3.InceptionV3\n",
    "#tf.keras.applications.inception_resnet_v2.InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import argparse\n",
    "#import cv2\n",
    "\n",
    "\n",
    "####################################################################\n",
    "#设置GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "\n",
    "#看具体的模型参数设置在:https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "MODELS = {\"ResNet50\":ResNet50, \"InceptionV3\":InceptionV3,\"DenseNet121\":DenseNet121,\n",
    "        \"DenseNet169\":DenseNet169,\"DenseNet201\":DenseNet201,\"Xception\":Xception, \n",
    "        \"InceptionResNetV2\":InceptionResNetV2,\"NASNetLarge\":NASNetLarge}\n",
    "#设置项\n",
    "Network = MODELS[\"ResNet50\"]\n",
    "#设置model,不同model放在不同文件夹下\n",
    "mymodel = \"ResNet50\"\n",
    "\n",
    "#设置预处理方式,当为224*224时选择如下:\n",
    "#ppreprocess = imagenet_utils.preprocess_input \n",
    "#为229*229,设置如下\n",
    "ppreprocess = preprocess_input\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\n",
    "#pooling: Optional pooling mode for feature extraction when include_top is False. - None means that the output of the model will be the 4D tensor output of the last convolutional layer. - 'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. - 'max' means that global max pooling will be applied.\n",
    "#cnn_model = Xception(include_top=False,input_shape=(width, width, 3), weights='imagenet',)\n",
    "#当include_top=False,即在最后卷积末尾新加pooling='avg'的全局均值采用,得到全局滤波器个数*1的二维输出\n",
    "cnn_model = Network(include_top=False, input_shape=(width, width, 3), weights='imagenet',pooling='avg')\n",
    "\n",
    "inputs = Input((width, width, 3))\n",
    "x = inputs\n",
    "x = Lambda(ppreprocess, name='preprocessing')(x)\n",
    "x = cnn_model(x)\n",
    "#下面是新加的层\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# n_class为对应属性的分类个数\n",
    "x = Dense(n_class, activation='softmax', name='softmax')(x)\n",
    "\n",
    "model = Model(inputs, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.12, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001)\n",
    "prefix_cls = cur_class.split('_')[0]\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../models/{0}/{0}_{1}.best.h5'.format(prefix_cls,mymodel), verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "h = model.fit(X_train, y_train, batch_size=32, epochs=80, \n",
    "              callbacks=[EarlyStopping(patience=3), checkpointer], \n",
    "              shuffle=True, \n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.legend(['acc', 'val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "#保存\n",
    "plt.savefig('../models/{0}/{0}_{1}.png'.format(prefix_cls, mymodel),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train, y_train, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_valid, y_valid, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../test/Tests/question.csv', header=None)\n",
    "df_test.columns = ['image_id', 'class', 'x']\n",
    "del df_test['x']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = df_test[(df_test['class'] == cur_class)].copy()\n",
    "df_load.reset_index(inplace=True)\n",
    "del df_load['index']\n",
    "\n",
    "print('{0}: {1}'.format(cur_class, len(df_load)))\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_load)\n",
    "X_test = np.zeros((n, width, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    X_test[i] = cv2.resize(cv2.imread('../test/{0}'.format(df_load['image_id'][i])), (width, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np = model.predict(X_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i, row in df_load.iterrows():\n",
    "    tmp_list = test_np[i]\n",
    "    tmp_result = ''\n",
    "    for tmp_ret in tmp_list:\n",
    "        tmp_result += '{:.4f};'.format(tmp_ret)\n",
    "        \n",
    "    result.append(tmp_result[:-1])\n",
    "\n",
    "df_load['result'] = result\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load.to_csv('../result/{1}/{0}_{1}.csv'.format(prefix_cls, mymodel), header=None, index=False)\n",
    "prefix_cls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
