{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T16:41:29.870316Z",
     "start_time": "2018-04-05T16:41:29.864801Z"
    }
   },
   "outputs": [],
   "source": [
    "#fai_model = torch.nn.DataParallel(module=fai_model, device_ids=[0, 3],output_device=[0])#前向在 device_ids，梯度汇总和更新在output_device上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T16:41:32.344862Z",
     "start_time": "2018-04-05T16:41:29.873238Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from torch.autograd import Variable ## torch中自动计算梯度模块\n",
    "import torch.nn as nn # 神经网络模块\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F  #神经网络模块中的常用功能 \n",
    "import torch.multiprocessing as mp\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import datasets, models\n",
    "from torchvision.models import *\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "plt.ion()   # interactive mode\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#显示中文字体设置\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Droid Sans Fallback\"]\n",
    "plt.rcParams['axes.unicode_minus'] = False #为了正常显示是\"-\"减号\n",
    "\n",
    "MODELS = {\"resnet50\":resnet50}\n",
    "classes = ['collar_design_labels', 'neck_design_labels'] \n",
    "label_count = {'coat_length_labels':8,\n",
    "               'collar_design_labels':5, \n",
    "               'lapel_design_labels':5,\n",
    "               'neck_design_labels':5,\n",
    "               'neckline_design_labels':10,\n",
    "               'pant_length_labels':6, \n",
    "               'skirt_length_labels':6, \n",
    "               'sleeve_length_labels':9}\n",
    "attrs_cls_label_map = {\n",
    "    'skirt_length_labels':['群不可见Invisible', '短群Short', '及膝群Knee', '旗袍裙群Midi', '及脚群Ankle', '接地群Floor'],\n",
    "    'coat_length_labels': ['衣不可见Invisible','高腰衣HighWaistLength','常规衣RegularLength','长衣LongLength','加长衣MicroLength',\n",
    "                           '及膝衣Knee Length','旗袍衣MidiLength','及地衣Ankle&FloorLength'],\n",
    "    'collar_design_labels': ['衣领不可见Invisible','衬衫领ShirtCollar','彼得潘女士小圆领PeterPan','清道夫领PuritanCollar','螺纹领RibCollar'],\n",
    "    'lapel_design_labels':['翻领不可见Invisible','缺口领Notched','无领Collarless','披肩围巾式领ShawlCollar','大号披肩围巾式领PlusSizeShawl'],\n",
    "    'neck_design_labels':['脖颈不可见Invisible','长高领TurtleNeck', '荷叶半高领RuffleSemi-HighCollar','低圆领LowTurtleNeck','翻领Draped Collar'],\n",
    "    'neckline_design_labels':['颈领线不可见Invisible','无肩带领StraplessNeck','深V领DeepVNeckline', '直领StraightNeck', 'V领VNeckline', \n",
    "                              '方领SquareNeckline', '出肩领OffShoulder', '圆领RoundNeckline', '桃形领SweatHeartNeck', '单肩领OneShoulderNeckline'],\n",
    "    'pant_length_labels':[ '裤不可见Invisible', '短裤ShortPant', '中裤Mid Length', '7分裤3/4Length', '9分裤CroppedPant', '长裤FullLength'],\n",
    "    'sleeve_length_labels':['袖不可见Invisible', '无袖Sleeveless', '杯袖CupSleeves', '短袖ShortSleeves', '肘中袖ElbowSleeves',\n",
    "                            '7分袖Sleeves', '及腕9分袖WristLength', '长袖LongSleeves', '超长袖ExtraLongSleeves']}\n",
    "\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,3\"\n",
    "#若gpu可用则返回True\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "#保存文件后缀,即月份和日为版本尾号\n",
    "#version = \"\"\n",
    "version = '0405'\n",
    "image_width = 224\n",
    "epochs_num = 30\n",
    "scheduler_step_size = 7 #设置含参变量的学习率变化，为多少个epoch做一次步进的衰减\n",
    "learning_rate = 0.001\n",
    "split_ratio = 0.2\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T16:41:32.401566Z",
     "start_time": "2018-04-05T16:41:32.349883Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义数据预处理\n",
    "fai_data_transforms = {\n",
    "                    'train': transforms.Compose([\n",
    "                        transforms.Resize(image_width, interpolation=2),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        #transforms.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "                        #transforms.RandomRotation(15, resample=False, expand=False, center=None),\n",
    "                        #transforms.RandomResizedCrop(image_width, scale=(0.95, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2),\n",
    "                        \n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                    ]),\n",
    "                    'val': transforms.Compose([\n",
    "                        #transforms.Resize(256),\n",
    "                        #transforms.CenterCrop(256,224),\n",
    "                        transforms.Resize(image_width, interpolation=2),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                    ]),\n",
    "                    'test': transforms.Compose([\n",
    "                        #transforms.Resize(256),\n",
    "                        #transforms.CenterCrop(256,224),\n",
    "                        transforms.Resize(image_width, interpolation=2),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                    ])\n",
    "}\n",
    "\n",
    "#定义数据集\n",
    "#当变换中含有 transforms.ToTensor(),处理后为RGB CHW 0-1.0数据，当含有transforms.Normalize()会返回一个分布在(x-mean)/std,这时值的范围就不是0-1.0了\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB').resize((224,224),Image.NEAREST)\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)\n",
    "#定义数据集\n",
    "class FaiTrainDataset(Dataset):\n",
    "    \"\"\"FaiTrainDataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train_csv_path_and_file, train_val_images_root_dir, train =True, split_ratio=0.2,transform=None,target_transform=None,loader=default_loader):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(train_csv_path_and_file)\n",
    "        #self.df_load = df.sample(frac=1).reset_index(drop=True)\n",
    "        self.df_load = self.df.copy()\n",
    "        #df.iloc[np.random.permutation(len(df))]\n",
    "        #self.x, self.y = self.df_load.ix[:,0],self.df_load.ix[:,2:]\n",
    "        #self.x_train,self.x_test,self.y_train,self.y_test = train_test_split(self.x,self.y,test_size=split_ratio,random_state=42)\n",
    "        self.split_ratio = split_ratio\n",
    "        self.cut_idx = int(len(self.df_load)-round(len(self.df_load)*self.split_ratio))#int(round(0.1 * self.df_load.shape[0]))\n",
    "        #self.b = int(len(self.df_load)*0.2)\n",
    "        self.df_train= self.df_load.iloc[:self.cut_idx]\n",
    "        self.df_val = self.df_load.iloc[self.cut_idx:]\n",
    "        \n",
    "        self.df_train_load = self.df_train.copy()\n",
    "        self.df_val_load = self.df_val.copy()\n",
    "        \n",
    "        self.df_train_load.columns = ['image_id', 'class', 'label']\n",
    "        self.df_val_load.columns = ['image_id', 'class', 'label']\n",
    "        \n",
    "        self.df_train_load.reset_index(inplace= True,drop=True)\n",
    "        self.df_val_load.reset_index(inplace= True,drop=True)\n",
    "        \n",
    "        self.train_images = self.df_train_load['image_id'].tolist()\n",
    "        self.train_labels = self.df_train_load['label'].tolist()\n",
    "        \n",
    "        self.val_images = self.df_val_load['image_id'].tolist()\n",
    "        self.val_labels = self.df_val_load['label'].tolist()\n",
    "        \n",
    "        n1=len(self.df_train_load)\n",
    "        n2=len(self.df_val_load)\n",
    "        \n",
    "        #不用转化为one-hot，根据所用的交叉熵形式\n",
    "        #self.train_y = np.zeros((n1, label_count[self.df_train_load['class'][0]]), dtype=np.uint8)\n",
    "        #self.val_y = np.zeros((n2, label_count[self.df_val_load['class'][0]]), dtype=np.uint8)\n",
    "        self.train_y = np.zeros(n1, dtype=np.uint8)\n",
    "        self.val_y = np.zeros(n2, dtype=np.uint8)\n",
    "        \n",
    "        for i in range(n1):\n",
    "            tmp_label1=self.train_labels[i]\n",
    "            self.train_y[i]=tmp_label1.find('y')\n",
    "        for j in range(n2):\n",
    "            tmp_label2=self.val_labels[j]\n",
    "            self.val_y[j]=tmp_label2.find('y')\n",
    "        self.train_data = list(zip(self.train_images,self.train_y))\n",
    "        self.val_data = list(zip(self.val_images,self.val_y))\n",
    "        #print(\"训练集：batch化需要的元组样例是{0}：\".format(self.train_data[0]))\n",
    "        #print(\"验证集：batch化需要的元组样例是{0}：\".format(self.val_data[0]))\n",
    "        \n",
    "        self.train_val_images_root_dir = train_val_images_root_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train == True:\n",
    "            return len(self.df_train_load)\n",
    "        else:\n",
    "            return len(self.df_val_load)\n",
    "\n",
    "    def __getitem__(self, index): #最终返回的是Tensor\n",
    "        if self.train == True:\n",
    "            train_image_path, train_label = self.train_data[index]\n",
    "            train_img_name = os.path.join(self.train_val_images_root_dir,train_image_path)\n",
    "            #image = io.imread(img_name) #用的skimage.io,读入为uint8，RGB，HWc图像\n",
    "            train_img = self.loader(train_img_name)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                train_img = self.transform(train_img) #处理后为RGB CHW ，个位整数的数据\n",
    "            if self.target_transform is not None:\n",
    "                train_label = self.target_transform(train_label)\n",
    "            return train_img,train_label\n",
    "        else:\n",
    "            val_image_path, val_label = self.val_data[index]\n",
    "            val_img_name = os.path.join(self.train_val_images_root_dir,val_image_path)\n",
    "            #image = io.imread(img_name) #用的skimage.io,读入为uint8，RGB，HWc图像\n",
    "            val_img = self.loader(val_img_name)\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                val_img = self.transform(val_img) ##处理后为RGB CHW ，个位整数的数据\n",
    "            if self.target_transform is not None:\n",
    "                val_label = self.target_transform(val_label)\n",
    "            return val_img,val_label #返回值是Tensor\n",
    "            \n",
    "        \n",
    "\n",
    "#定义测试数据集\n",
    "class FaiTestDataset(Dataset):\n",
    "    \"\"\"FaiTestDataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, test_csv_path_and_file, test_images_root_dir, attr, transform=None,target_transform=None,loader=default_loader):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "       \n",
    "        self.df_test = pd.read_csv(test_csv_path_and_file)\n",
    "        #定义各列名称\n",
    "        self.df_test.columns = ['image_id', 'class', 'x']\n",
    "        del self.df_test['x']\n",
    "        self.attr = attr\n",
    "        \n",
    "        self.df_test_load = self.df_test[(self.df_test['class'] == self.attr)].copy()\n",
    "        self.df_test_load.reset_index(inplace= True,drop= True)\n",
    "        \n",
    "        self.test_images = self.df_test_load['image_id'].tolist()\n",
    "        #n=len(self.df_test_load)\n",
    "        #self.test_y = np.zeros((n, label_count[self.attr]), dtype=np.uint8)\n",
    "        #self.test_data = list(zip(self.test_images,self.test_y))\n",
    "        self.test_data = self.test_images\n",
    "        #print(\"测试集（不含label）：batch化需要的元组样例是{0}：\".format(self.test_data[0]))\n",
    "    \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        self.test_images_root_dir = test_images_root_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_test_load)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_path = self.test_data[index]\n",
    "        test_img_name = os.path.join(self.test_images_root_dir,test_path)\n",
    "        #test_image = io.imread(test_img_name) 只能用PIL读图像，因为系统要求\n",
    "        test_img = self.loader(test_img_name)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            test_img = self.transform(test_img) #处理后为RGB CHW ，个位整数的数据\n",
    "\n",
    "        return test_img #返回值为Tensor\n",
    "\n",
    "#测试定义的数据,一个batch的数据可视化\n",
    "def fai_augment_visualize(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0)) #若用cv显示则是：inp = inp.numpy().transpose((1, 2, 0))*255 \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    #plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    # opencv\n",
    "    #img2 = data[i][0].numpy()*255\n",
    "    #img2 = img2.astype('uint8')\n",
    "    #img2 = np.transpose(img2, (1,2,0))\n",
    "    #img2=img2[:,:,::-1]#RGB->BGR\n",
    "    #cv2.imshow('img2', img2)\n",
    "    #cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T16:41:32.515669Z",
     "start_time": "2018-04-05T16:41:32.404640Z"
    }
   },
   "outputs": [],
   "source": [
    "########################### 定义训练和测试及其他可视化函数 #######################\n",
    "#定义训练模型的具体步骤及参数设置\n",
    "def fai_train_model(model, criterion, optimizer, scheduler, batch_size,split_ratio,num_epochs,attr,model_key,version):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    #测试训练，验证和测试数据上的数据增强\n",
    "    training_fai_train_dataset = FaiTrainDataset(train_csv_path_and_file='../train/Annotations/{0}.csv'.format(attr),\n",
    "                                       train_val_images_root_dir='../train/',\n",
    "                                       train =True, split_ratio=split_ratio,\n",
    "                                       transform= fai_data_transforms['train'])\n",
    "    training_fai_val_dataset = FaiTrainDataset(train_csv_path_and_file='../train/Annotations/{0}.csv'.format(attr),\n",
    "                                       train_val_images_root_dir='../train/',\n",
    "                                       train =False, split_ratio=split_ratio,\n",
    "                                       transform= fai_data_transforms['val'])\n",
    "    training_image_datasets = {'train': training_fai_train_dataset, 'val':training_fai_val_dataset}\n",
    "\n",
    "    #关于训练验证集的封装\n",
    "    training_dataloaders = {x: torch.utils.data.DataLoader(training_image_datasets[x], batch_size=batch_size,shuffle=True, num_workers=8)\n",
    "                   for x in ['train', 'val']}\n",
    "    training_dataset_lengths = {x: len(training_image_datasets[x]) for x in ['train', 'val']}\n",
    "    print(\"摘要：Attr:{0}.Train样本数：{1} ，Val样本数：{2}\".format(attr,training_dataset_lengths['train'],training_dataset_lengths['val']))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            #每batch一次train，就val一次\n",
    "            if phase == 'train':\n",
    "                #与Optimizer类似的是，其主要功能体现在step()方法中，用于更新optimizer对象每个param_group字典的lr键的值。\n",
    "                #scheduler = torch.optim.ReduceLROnPlateau(optimizer, 'min')，这应用在函数体外\n",
    "                scheduler.step() #如scheduler.step(val_loss)\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in training_dataloaders[phase]:\n",
    "                # get the inputs(每次一个batch)\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    \n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.long().cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs,volatile=True), Variable(labels,volatile=True)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1) #第一个是最大概率值的张量，第二个是索引值\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                # 即用的总loss而不是平均loss\n",
    "                running_loss += loss.data[0] * inputs.size(0) #inputs.size(0)：每个batchsize的大小\n",
    "                running_corrects += torch.sum(preds == labels.data) #可知标签不用转化为one-hot\n",
    "\n",
    "            epoch_loss = running_loss / training_dataset_lengths[phase]\n",
    "            epoch_acc = running_corrects / training_dataset_lengths[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    #保存最好的模型\n",
    "    print(\"开始保存模型\")\n",
    "    prefix_cls = attr.split('_')[0]\n",
    "    PATH = '../models/{0}/pytorch_{0}_{1}_{2}'.format(prefix_cls, model_key, version)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    #model = 你定义的模型class封装\n",
    "    #model.load_state_dict(torch.load(PATH))\n",
    "    print(\"保存最好的模型完成\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "######这是将训练好的模型用于测试集上，输出对应属性的也测结果到csv文件\n",
    "#\n",
    "def fai_predict(predictor,attr,model_key,version): \n",
    "    fai_test_dataset = FaiTestDataset(test_csv_path_and_file='../test/Tests/question.csv',\n",
    "                                      test_images_root_dir='../test/',\n",
    "                                      attr =attr,\n",
    "                                      transform= fai_data_transforms['test'])\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(fai_test_dataset, batch_size=32,shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = predictor\n",
    "    model.train(False)\n",
    "    model.eval() #model.train(False)  # Set model to evaluate mode\n",
    "    #len(test_dataloader)返回的是len(相应dataset)/batch_size\n",
    "    #for i_batch in tqdm(range(len(test_dataloader))):\n",
    "    #在测试集上预测并保存结果\n",
    "    df_test_load = fai_test_dataset.df_test_load\n",
    "    print(\"测试属性：Attr:{0}\".format(attr))\n",
    "    print('测试数据集的样本数为：{0},迭代器需要的迭代次数是：{1}次batchsize的迭代'.format(len(fai_test_dataset),len(test_dataloader)))\n",
    "    \n",
    "    result = []\n",
    "    prefix_cls = attr.split('_')[0]\n",
    "    for i,batch_x in enumerate(test_dataloader):\n",
    "        batch_x = Variable(batch_x, volatile=True)\n",
    "        out = model(batch_x)\n",
    "        out = F.softmax(out,dim=1).cpu() #把输出的正负数转到0-1之间\n",
    "        test_np=out.data.numpy()\n",
    "        \n",
    "        #tmp_list = test_np.tolist()\n",
    "        for jj in test_np:\n",
    "            \n",
    "            tmp_result = ''\n",
    "            for tmp_ret in jj:\n",
    "                tmp_result += '{:.5f};'.format(tmp_ret)\n",
    "                #不要最后一个分号\n",
    "            result.append(tmp_result[:-1])\n",
    "    \n",
    "    #预测结果导入内存表格的result列\n",
    "    df_test_load['result'] = result     \n",
    "    df_test_load.to_csv('../result/pytorch/pytorch_{0}_{1}_{2}.csv'.format(prefix_cls, model_key, version), header=None, index=False) \n",
    "    print('#######完成{0}:{1}下的测试机上的csv文件输出'.format(model_key,attr))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-05T16:52:54.660650Z",
     "start_time": "2018-04-05T16:41:32.518443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################在resnet50下训练8个分类器####################\n",
      "\n",
      "#######resnet50:collar_design_labels####################\n",
      "摘要：Attr:collar_design_labels.Train样本数：6714 ，Val样本数：1678\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.3834 Acc: 0.4200\n",
      "val Loss: 1.1742 Acc: 0.5298\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.0458 Acc: 0.5977\n",
      "val Loss: 1.0004 Acc: 0.6037\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.8753 Acc: 0.6631\n",
      "val Loss: 0.8816 Acc: 0.6657\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.7353 Acc: 0.7230\n",
      "val Loss: 0.8349 Acc: 0.6853\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.6144 Acc: 0.7800\n",
      "val Loss: 0.7958 Acc: 0.7056\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.5112 Acc: 0.8187\n",
      "val Loss: 0.7701 Acc: 0.7151\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.4240 Acc: 0.8558\n",
      "val Loss: 0.8008 Acc: 0.7116\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.3379 Acc: 0.8984\n",
      "val Loss: 0.7541 Acc: 0.7300\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.3173 Acc: 0.9048\n",
      "val Loss: 0.7594 Acc: 0.7253\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.3158 Acc: 0.9005\n",
      "val Loss: 0.7548 Acc: 0.7294\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.2958 Acc: 0.9132\n",
      "val Loss: 0.7552 Acc: 0.7324\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.2930 Acc: 0.9124\n",
      "val Loss: 0.7541 Acc: 0.7348\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.2919 Acc: 0.9087\n",
      "val Loss: 0.7591 Acc: 0.7294\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.2827 Acc: 0.9169\n",
      "val Loss: 0.7574 Acc: 0.7330\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.2694 Acc: 0.9236\n",
      "val Loss: 0.7556 Acc: 0.7318\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.2691 Acc: 0.9223\n",
      "val Loss: 0.7548 Acc: 0.7366\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.2620 Acc: 0.9233\n",
      "val Loss: 0.7528 Acc: 0.7324\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.2690 Acc: 0.9231\n",
      "val Loss: 0.7620 Acc: 0.7312\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.2660 Acc: 0.9228\n",
      "val Loss: 0.7541 Acc: 0.7300\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.2630 Acc: 0.9261\n",
      "val Loss: 0.7582 Acc: 0.7330\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.2647 Acc: 0.9242\n",
      "val Loss: 0.7578 Acc: 0.7306\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.2607 Acc: 0.9257\n",
      "val Loss: 0.7553 Acc: 0.7360\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.2653 Acc: 0.9214\n",
      "val Loss: 0.7528 Acc: 0.7330\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.2696 Acc: 0.9211\n",
      "val Loss: 0.7641 Acc: 0.7294\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.2573 Acc: 0.9287\n",
      "val Loss: 0.7519 Acc: 0.7342\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.2570 Acc: 0.9252\n",
      "val Loss: 0.7616 Acc: 0.7300\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.2645 Acc: 0.9209\n",
      "val Loss: 0.7543 Acc: 0.7294\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.2668 Acc: 0.9194\n",
      "val Loss: 0.7553 Acc: 0.7312\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.2753 Acc: 0.9181\n",
      "val Loss: 0.7588 Acc: 0.7306\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.2615 Acc: 0.9264\n",
      "val Loss: 0.7604 Acc: 0.7336\n",
      "\n",
      "Training complete in 6m 30s\n",
      "Best val Acc: 0.736591\n",
      "开始保存模型\n",
      "保存最好的模型完成\n",
      "#######resnet50:collar_design_labels训练完毕，开始在测试集上测试\n",
      "测试属性：Attr:collar_design_labels\n",
      "测试数据集的样本数为：1081,迭代器需要的迭代次数是：34次batchsize的迭代\n",
      "#######完成resnet50:collar_design_labels下的测试机上的csv文件输出\n",
      "#######resnet50:neck_design_labels####################\n",
      "摘要：Attr:neck_design_labels.Train样本数：4556 ，Val样本数：1139\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.4885 Acc: 0.3483\n",
      "val Loss: 1.3445 Acc: 0.4416\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.2553 Acc: 0.4930\n",
      "val Loss: 1.2447 Acc: 0.5004\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.0987 Acc: 0.5729\n",
      "val Loss: 1.1414 Acc: 0.5408\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.9485 Acc: 0.6337\n",
      "val Loss: 1.0584 Acc: 0.5812\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.8208 Acc: 0.6846\n",
      "val Loss: 1.0042 Acc: 0.6155\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.7067 Acc: 0.7371\n",
      "val Loss: 0.9746 Acc: 0.6277\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.5963 Acc: 0.7856\n",
      "val Loss: 0.9261 Acc: 0.6435\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.4908 Acc: 0.8461\n",
      "val Loss: 0.9144 Acc: 0.6409\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.4830 Acc: 0.8450\n",
      "val Loss: 0.9121 Acc: 0.6453\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.4645 Acc: 0.8503\n",
      "val Loss: 0.9058 Acc: 0.6427\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.4609 Acc: 0.8532\n",
      "val Loss: 0.9084 Acc: 0.6558\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.4471 Acc: 0.8613\n",
      "val Loss: 0.9083 Acc: 0.6488\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.4399 Acc: 0.8580\n",
      "val Loss: 0.9029 Acc: 0.6567\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.4278 Acc: 0.8668\n",
      "val Loss: 0.9065 Acc: 0.6558\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.4100 Acc: 0.8782\n",
      "val Loss: 0.9134 Acc: 0.6453\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.4168 Acc: 0.8749\n",
      "val Loss: 0.9064 Acc: 0.6453\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.4134 Acc: 0.8762\n",
      "val Loss: 0.9026 Acc: 0.6479\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.4161 Acc: 0.8727\n",
      "val Loss: 0.9105 Acc: 0.6550\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.4159 Acc: 0.8712\n",
      "val Loss: 0.9041 Acc: 0.6488\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.4120 Acc: 0.8826\n",
      "val Loss: 0.9075 Acc: 0.6585\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.4012 Acc: 0.8821\n",
      "val Loss: 0.9061 Acc: 0.6506\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.4187 Acc: 0.8775\n",
      "val Loss: 0.9134 Acc: 0.6576\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.4059 Acc: 0.8824\n",
      "val Loss: 0.9045 Acc: 0.6541\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.4029 Acc: 0.8793\n",
      "val Loss: 0.9039 Acc: 0.6532\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.4035 Acc: 0.8806\n",
      "val Loss: 0.9057 Acc: 0.6594\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.4062 Acc: 0.8837\n",
      "val Loss: 0.9093 Acc: 0.6585\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.4084 Acc: 0.8723\n",
      "val Loss: 0.9105 Acc: 0.6506\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.4109 Acc: 0.8771\n",
      "val Loss: 0.9106 Acc: 0.6611\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.4066 Acc: 0.8749\n",
      "val Loss: 0.9104 Acc: 0.6558\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.4138 Acc: 0.8738\n",
      "val Loss: 0.9036 Acc: 0.6506\n",
      "\n",
      "Training complete in 4m 42s\n",
      "Best val Acc: 0.661106\n",
      "开始保存模型\n",
      "保存最好的模型完成\n",
      "#######resnet50:neck_design_labels训练完毕，开始在测试集上测试\n",
      "测试属性：Attr:neck_design_labels\n",
      "测试数据集的样本数为：708,迭代器需要的迭代次数是：23次batchsize的迭代\n",
      "#######完成resnet50:neck_design_labels下的测试机上的csv文件输出\n"
     ]
    }
   ],
   "source": [
    "################################### 实例化训练和测试 ############################\n",
    "#加载预训练模型并重写全连接层。\n",
    "\n",
    "#state_dict = torch.utils.model_zoo.load_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth')\n",
    "#the_model = TheModelClass(*args, **kwargs)\n",
    "#the_model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "#下面是冻结卷积层的方法\n",
    "# fai_model = torchvision.models.resnet18(pretrained=True)\n",
    "# for param in fai_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "#model.fc = nn.Linear(512, 100)\n",
    "# Optimize only the classifier\n",
    "#optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
    "for KEY, MODLE in MODELS.items():\n",
    "    print('######################在{0}下训练8个分类器####################'.format(KEY))\n",
    "    print()\n",
    "    for cur_class in classes:\n",
    "\n",
    "        print('#######{0}:{1}####################'.format(KEY,cur_class ))\n",
    "        #预结构\n",
    "        fai_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        #改进的自定义添加\n",
    "        num_ftrs = fai_model.fc.in_features\n",
    "        fai_model.fc = nn.Linear(num_ftrs, label_count[cur_class])\n",
    "\n",
    "        \n",
    "        #打印含参数各层的名字\n",
    "        #params = fai_model.state_dict()\n",
    "        #for k,v in params.items():\n",
    "        #    print(k)#打印网络中的变量名\n",
    "        #print(fai_model)#可查最后一层Module类对象的名和输入参数，输出参数名，如(fc): Linear(in_features=512, out_features=5, bias=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #设置采用多分类的交叉熵loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # 设置优化器，fai_model.parameters()表示优化全部参数@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@这里可设置两部优化法\n",
    "        optimizer = optim.SGD(fai_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "        # Decay LR by a factor of 0.1 every 7 epochs\n",
    "        #与Optimizer类似的是，其主要功能体现在step()方法中，用于更新optimizer对象每个param_group字典的lr键的值。\n",
    "        #scheduler = torch.optim.ReduceLROnPlateau(optimizer, 'min')   scheduler.step(val_loss)\n",
    "        fai_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=0.1) \n",
    "        #训练和评估\n",
    "        fai_model = torch.nn.DataParallel(module=fai_model.cuda(), device_ids=[0, 3],output_device=0)#前向在 device_ids，梯度汇总和更新在output_device上\n",
    "        model = fai_train_model(fai_model, criterion, optimizer, fai_lr_scheduler, batch_size=batch_size,split_ratio=split_ratio,num_epochs=epochs_num,attr=cur_class,model_key=KEY,version=version)\n",
    "        #在测试集上运用训练好的模型，输出csv文件\n",
    "        print('#######{0}:{1}训练完毕，开始在测试集上测试'.format(KEY,cur_class ))\n",
    "        #在gpu上测试\n",
    "        fai_predict(predictor = model,attr=cur_class,model_key=KEY,version=version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
